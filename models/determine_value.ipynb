{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:19,368 - INFO - Initialized MLB Trade Simulator value determination module\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MLB Trade Simulator - Value Determination Module\n",
    "Author: Niels Christoffersen\n",
    "Version: 1.0\n",
    "Last Updated: 12/23/2024\n",
    "\n",
    "This module calculates player values based on WAR projections and contract status.\n",
    "It handles data loading, cleaning, and value calculations for MLB players.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import logging\n",
    "from enum import Enum\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Type aliases\n",
    "PathLike = str | Path\n",
    "\n",
    "# Global constants\n",
    "ROOT_DIR = Path(os.getcwd()).parent  # Changed from Path(__file__).parent.parent\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "GENERATED_DIR = DATA_DIR / 'generated'\n",
    "OUTPUT_DIR = GENERATED_DIR / 'value_by_year'\n",
    "HITTER_COLUMNS = [\n",
    "    'Name', 'Age', 'IDfg', 'BB%', 'K%', 'AVG', 'OBP', 'SLG', 'wOBA', \n",
    "    'wRC+', 'Off', 'BsR', 'Def', 'WAR', 'HR', '2B', '3B', 'SB', 'CS', 'R', 'RBI'\n",
    "]\n",
    "\n",
    "PITCHER_COLUMNS = [\n",
    "    'Name', 'Age', 'IDfg', 'ERA','FIP', 'SIERA', 'K%', 'BB%', 'WAR'\n",
    "]\n",
    "\n",
    "\n",
    "class PlayerStatus(Enum):\n",
    "    PRE_ARB = \"Pre-ARB\"\n",
    "    ARB1 = \"ARB1\"\n",
    "    ARB2 = \"ARB2\"\n",
    "    ARB3 = \"ARB3\"\n",
    "    FREE_AGENT = \"FA\"\n",
    "    SIGNED = \"Signed\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "STATUS_MAPPINGS = {\n",
    "    'PRE-ARB': PlayerStatus.PRE_ARB,\n",
    "    'PRE ARB': PlayerStatus.PRE_ARB,\n",
    "    'ROOKIE': PlayerStatus.PRE_ARB,\n",
    "    'MIN': PlayerStatus.PRE_ARB,\n",
    "    'ARB 1': PlayerStatus.ARB1,\n",
    "    'ARB1': PlayerStatus.ARB1,\n",
    "    'ARB 2': PlayerStatus.ARB2,\n",
    "    'ARB2': PlayerStatus.ARB2,\n",
    "    'ARB 3': PlayerStatus.ARB3,\n",
    "    'ARB3': PlayerStatus.ARB3,\n",
    "    'ARB 4': PlayerStatus.ARB3,\n",
    "    'UFA': PlayerStatus.FREE_AGENT,\n",
    "    'FA': PlayerStatus.FREE_AGENT,\n",
    "}\n",
    "# Ensure required directories exist\n",
    "for directory in [DATA_DIR, GENERATED_DIR, OUTPUT_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    logger.debug(f\"Verified directory exists: {directory}\")\n",
    "\n",
    "logger.info(\"Initialized MLB Trade Simulator value determination module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:19,402 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2025.csv\n",
      "2025-01-21 23:20:19,414 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2026.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:19,422 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2027.csv\n",
      "2025-01-21 23:20:19,431 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2028.csv\n",
      "2025-01-21 23:20:19,441 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2029.csv\n",
      "2025-01-21 23:20:19,450 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2030.csv\n",
      "2025-01-21 23:20:19,459 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2031.csv\n",
      "2025-01-21 23:20:19,469 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2032.csv\n",
      "2025-01-21 23:20:19,475 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2033.csv\n",
      "2025-01-21 23:20:19,484 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2034.csv\n",
      "2025-01-21 23:20:19,491 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2035.csv\n",
      "2025-01-21 23:20:19,498 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2036.csv\n",
      "2025-01-21 23:20:19,504 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2037.csv\n",
      "2025-01-21 23:20:19,510 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2038.csv\n",
      "2025-01-21 23:20:19,517 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\SP_Predictions_2039.csv\n",
      "2025-01-21 23:20:19,533 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2025.csv\n",
      "2025-01-21 23:20:19,544 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2026.csv\n",
      "2025-01-21 23:20:19,553 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2027.csv\n",
      "2025-01-21 23:20:19,562 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2028.csv\n",
      "2025-01-21 23:20:19,574 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2029.csv\n",
      "2025-01-21 23:20:19,584 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2030.csv\n",
      "2025-01-21 23:20:19,593 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2031.csv\n",
      "2025-01-21 23:20:19,602 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2032.csv\n",
      "2025-01-21 23:20:19,612 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2033.csv\n",
      "2025-01-21 23:20:19,620 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2034.csv\n",
      "2025-01-21 23:20:19,629 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2035.csv\n",
      "2025-01-21 23:20:19,643 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2036.csv\n",
      "2025-01-21 23:20:19,656 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2037.csv\n",
      "2025-01-21 23:20:19,666 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2038.csv\n",
      "2025-01-21 23:20:19,675 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\RP_Predictions_2039.csv\n",
      "2025-01-21 23:20:19,688 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2025.csv\n",
      "2025-01-21 23:20:19,709 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2026.csv\n",
      "2025-01-21 23:20:19,731 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2027.csv\n",
      "2025-01-21 23:20:19,749 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2028.csv\n",
      "2025-01-21 23:20:19,775 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2029.csv\n",
      "2025-01-21 23:20:19,800 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2030.csv\n",
      "2025-01-21 23:20:19,824 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2031.csv\n",
      "2025-01-21 23:20:19,848 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2032.csv\n",
      "2025-01-21 23:20:19,877 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2033.csv\n",
      "2025-01-21 23:20:19,902 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2034.csv\n",
      "2025-01-21 23:20:19,929 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2035.csv\n",
      "2025-01-21 23:20:19,953 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2036.csv\n",
      "2025-01-21 23:20:19,975 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2037.csv\n",
      "2025-01-21 23:20:19,993 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2038.csv\n",
      "2025-01-21 23:20:20,013 - INFO - Loading c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\Batter_Predictions_2039.csv\n",
      "2025-01-21 23:20:20,060 - INFO - Loaded 3832 SP, 6347 RP, 6825 batter, and 3821 salary records\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "PREDICTION_YEARS = range(2025, 2040)\n",
    "REQUIRED_COLUMNS = {\n",
    "    'predictions': ['Name', 'IDfg', 'Age', 'WAR'],\n",
    "    'salary': ['Name', 'IDfg', 'Salary', 'Contract_Status']\n",
    "}\n",
    "\n",
    "def validate_files_exist(pattern: str, years: range) -> None:\n",
    "    \"\"\"Validate prediction files exist for given years.\"\"\"\n",
    "    missing_files = [\n",
    "        f\"{pattern}_{year}.csv\" \n",
    "        for year in years \n",
    "        if not (GENERATED_DIR / f\"{pattern}_{year}.csv\").exists()\n",
    "    ]\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Missing files: {', '.join(missing_files)}\")\n",
    "\n",
    "def load_prediction_files(pattern: str, years: range = PREDICTION_YEARS) -> DataFrame:\n",
    "    \"\"\"Load and combine prediction CSVs with validation.\"\"\"\n",
    "    validate_files_exist(pattern, years)\n",
    "    dfs = []\n",
    "    \n",
    "    for year in years:\n",
    "        file_path = GENERATED_DIR / f\"{pattern}_{year}.csv\"\n",
    "        logger.info(f\"Loading {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            missing_cols = set(REQUIRED_COLUMNS['predictions']) - set(df.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns in {file_path}: {missing_cols}\")\n",
    "                \n",
    "            df['prediction_year'] = year\n",
    "            dfs.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {file_path}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Main data loading\n",
    "try:\n",
    "    sp_data = load_prediction_files('SP_Predictions')\n",
    "    rp_data = load_prediction_files('RP_Predictions')\n",
    "    batter_data = load_prediction_files('Batter_Predictions')\n",
    "    salary_data = pd.read_csv(DATA_DIR / 'MLB_SALARY_DATA.csv')\n",
    "    \n",
    "    logger.info(f\"Loaded {len(sp_data)} SP, {len(rp_data)} RP, \"\n",
    "                f\"{len(batter_data)} batter, and {len(salary_data)} salary records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Critical error during data loading: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def integrate_historical_data(batter_data: pd.DataFrame,\n",
    "                            sp_data: pd.DataFrame,\n",
    "                            rp_data: pd.DataFrame,\n",
    "                            batting_history: pd.DataFrame,\n",
    "                            pitching_history: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Integrate historical stats with prediction data.\"\"\"\n",
    "    \n",
    "    # Get player IDs from prediction data\n",
    "    batter_ids = set(batter_data['IDfg'].unique())\n",
    "    sp_ids = set(sp_data['IDfg'].unique())\n",
    "    rp_ids = set(rp_data['IDfg'].unique())\n",
    "    \n",
    "    # Filter historical data to prediction players only\n",
    "    batting_history = batting_history[batting_history['IDfg'].isin(batter_ids)]\n",
    "    historical_sp = pitching_history[pitching_history['IDfg'].isin(sp_ids)]\n",
    "    historical_rp = pitching_history[pitching_history['IDfg'].isin(rp_ids)]\n",
    "    \n",
    "    # Standardize column names\n",
    "    sp_data = sp_data.copy().rename(columns={'Season': 'Year'})\n",
    "    rp_data = rp_data.copy().rename(columns={'Season': 'Year'})\n",
    "    batting_history = batting_history.rename(columns={'Season': 'Year'})\n",
    "    historical_sp = historical_sp.rename(columns={'Season': 'Year'})\n",
    "    historical_rp = historical_rp.rename(columns={'Season': 'Year'})\n",
    "    \n",
    "    # Get common columns\n",
    "    batting_cols = [col for col in batter_data.columns if col in batting_history.columns]\n",
    "    pitching_cols = [col for col in sp_data.columns if col in historical_sp.columns]\n",
    "    \n",
    "    # Combine data\n",
    "    combined_batting = pd.concat([\n",
    "        batter_data[batting_cols],\n",
    "        batting_history[batting_cols]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    combined_sp = pd.concat([\n",
    "        sp_data[pitching_cols],\n",
    "        historical_sp[pitching_cols]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    combined_rp = pd.concat([\n",
    "        rp_data[pitching_cols],\n",
    "        historical_rp[pitching_cols]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Sort and deduplicate\n",
    "    for df in [combined_batting, combined_sp, combined_rp]:\n",
    "        df.sort_values(['IDfg', 'Year'], inplace=True)\n",
    "        df.drop_duplicates(subset=['IDfg', 'Year'], keep='first', inplace=True)\n",
    "    \n",
    "    logger.info(f\"Added {len(combined_batting) - len(batter_data)} historical batting records\")\n",
    "    logger.info(f\"Added {len(combined_sp) - len(sp_data)} historical SP records\")\n",
    "    logger.info(f\"Added {len(combined_rp) - len(rp_data)} historical RP records\")\n",
    "    \n",
    "    return combined_batting, combined_sp, combined_rp\n",
    "\n",
    "try:\n",
    "    batting_history = pd.read_csv('../data/mlb_batting_data_2000_2024.csv')\n",
    "    pitching_history = pd.read_csv('../data/mlb_pitching_data_2000_2024.csv')\n",
    "    \n",
    "    batter_data, sp_data, rp_data = integrate_historical_data(\n",
    "        batter_data,\n",
    "        sp_data,\n",
    "        rp_data,\n",
    "        batting_history,\n",
    "        pitching_history\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to integrate historical data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Positions, and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique status values found:\n",
      "[nan 'Pre-Arb' 'ARB 1' 'ARB 2' 'ARB 3' 'Club' 'UFA' 'Vesting' 'Opt-Out'\n",
      " 'Player' 'Estimate' 'PRE-ARB' '-' 'ARB 4' 'Arb Avoided' '$3,516,480'\n",
      " '$16,000,000' '$8,000,000' '$9,000,000' '$3,500,000' '$9,500,000'\n",
      " '$860,000' '$820,000' 'ARB 1 (S2)' '$11,000,000' '$3,844,100'\n",
      " '$18,000,000' '$13,000,000' '$8,500,000' '$15,600,000' '$18,600,000'\n",
      " '$10,750,000' 'Mutual' '$2,250,000' '$14,000,000' '$26,000,000'\n",
      " '$28,000,000' '$27,000,000' '$21,000,000' '$19,000,000' '$8,600,000'\n",
      " '$17,100,000' '$15,100,000' '$1,950,000' '$1,750,000' 'RFA / QO'\n",
      " '$22,000,000' '$17,000,000' '$23,000,000' '$25,000,000' '$4,000,000'\n",
      " '$10,000,000' '$15,000,000' '$32,500,000' '$12,500,000' '$15,950,000'\n",
      " '$17,700,000' '$6,000,000' 'Arb Avoided #' '$17,666,667' '$37,166,667'\n",
      " '$37,216,667' '$37,116,666' '$37,116,674' '$10,015,872' '$28,071,428'\n",
      " '$36,571,428' '$38,571,428' '$38,571,432' '$21,225,000' '$2,370,968'\n",
      " '$2,500,000' '$2,000,000' '$22,500,000' '$30,000,000' '$35,000,000'\n",
      " 'arbitration-bypassed' '$4,500,000' '$34,100,000' '$18,500,000'\n",
      " '$20,500,000' '$15,750,000' '$20,750,000' '$850,000' '$40,000,000'\n",
      " '$14,500,000' '$31,500,000' '$22,833,333' '$27,833,333' '$27,833,334'\n",
      " '$1,800,000' '$11,538,462' '$11,168,092' '$28,088,462' '$27,638,462'\n",
      " '$27,538,462' '$23,538,462' '$27,272,727' '$27,272,730' '$24,571,428'\n",
      " '$24,571,432' '$42,000,000' '$23,875,000' '$20,000,000' '$250,000'\n",
      " '$6,283,000' '$17,090,909' '$25,090,909' '$39,090,909' '$39,090,910'\n",
      " '$25,454,545' '$25,454,550' '$13,142,857' '$31,142,857' '$31,142,858'\n",
      " '$25,166,666' '$25,166,668' '$6,583,333' '$12,000,000' '$20,416,666'\n",
      " '$10,500,000' '$2,500,026' '$7,500,000' '$33,000,000' '$35,500,000'\n",
      " '$29,000,000' '$24,000,000' '$5,500,000' '$16,500,000' '$1,250,000'\n",
      " '$23,666,666' '$29,666,666' '$24,166,666' '$24,166,667' '$2,962,963']\n"
     ]
    }
   ],
   "source": [
    "def analyze_status_values(salary_df):\n",
    "    \"\"\"Print unique status values from salary data\"\"\"\n",
    "    unique_statuses = salary_df['Status'].unique()\n",
    "    print(\"Unique status values found:\")\n",
    "    print(unique_statuses)\n",
    "\n",
    "analyze_status_values(salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:20,118 - INFO - SP columns: ['Name', 'Season', 'Age', 'Role', 'IDfg', 'ERA', 'FIP', 'SIERA', 'K%', 'BB%', 'HR/9', 'SwStr%', 'Contact%', 'O-Swing%', 'Z-Contact%', 'F-Strike%', 'Zone%', 'CSW%', 'CStr%', 'GB%', 'FB%', 'IFFB%', 'HR/FB', 'Soft%', 'Med%', 'Hard%', 'FBv', 'IP', 'GS', 'G', 'WAR', 'prediction_year', 'position_group', 'Position']\n",
      "2025-01-21 23:20:20,120 - INFO - RP columns: ['Name', 'Season', 'Age', 'Role', 'IDfg', 'ERA', 'FIP', 'SIERA', 'K%', 'BB%', 'HR/9', 'SwStr%', 'Contact%', 'O-Swing%', 'Z-Contact%', 'F-Strike%', 'Zone%', 'CSW%', 'CStr%', 'GB%', 'FB%', 'IFFB%', 'HR/FB', 'Soft%', 'Med%', 'Hard%', 'FBv', 'IP', 'GS', 'G', 'WAR', 'prediction_year', 'position_group', 'Position']\n",
      "2025-01-21 23:20:20,122 - INFO - Batter columns: ['Name', 'Age', 'Year', 'IDfg', 'BB%', 'K%', 'BABIP', 'AVG', 'OBP', 'SLG', 'wOBA', 'wRC+', 'def_value', 'Position', 'BsR', 'wSB', 'UBR', 'wGDP', 'SB', 'CS', 'Off', 'Def', 'WAR', 'PA', 'G', 'HR', '2B', '3B', 'RBI', 'R', 'prediction_year', 'position_group']\n",
      "2025-01-21 23:20:20,142 - INFO - Successfully merged 17004 player predictions\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Position Grouping and Data Merging\n",
    "- Groups player positions into SP/RP/POS categories\n",
    "- Merges prediction datasets\n",
    "- Validates data quality\n",
    "- Provides summary statistics\n",
    "\"\"\"\n",
    "\n",
    "# Add position grouping\n",
    "sp_data['position_group'] = 'SP'\n",
    "rp_data['position_group'] = 'RP'\n",
    "batter_data['position_group'] = 'POS'\n",
    "\n",
    "sp_data['Position'] = sp_data['position_group']\n",
    "rp_data['Position'] = rp_data['position_group']\n",
    "\n",
    "def merge_prediction_data(sp_df, rp_df, batter_df):\n",
    "    \"\"\"Merge prediction datasets with validation.\"\"\"\n",
    "    required_cols = [\n",
    "        'Name', 'IDfg', 'position_group', 'Age', \n",
    "        'prediction_year', 'WAR', 'Position'\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"SP columns: {sp_df.columns.tolist()}\")\n",
    "    logger.info(f\"RP columns: {rp_df.columns.tolist()}\")\n",
    "    logger.info(f\"Batter columns: {batter_df.columns.tolist()}\")\n",
    "    \n",
    "    # Combine datasets\n",
    "    player_predictions = pd.concat([\n",
    "        sp_df[sp_df.columns.intersection(required_cols + ['Position'])],\n",
    "        rp_df[rp_df.columns.intersection(required_cols + ['Position'])],\n",
    "        batter_df[batter_df.columns.intersection(required_cols + ['Position'])]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Verify Position exists\n",
    "    if 'Position' not in player_predictions.columns:\n",
    "        raise ValueError(\"Position column lost during merge\")\n",
    "        \n",
    "    return player_predictions\n",
    "\n",
    "# Merge data and generate summary\n",
    "try:\n",
    "    player_predictions = merge_prediction_data(sp_data, rp_data, batter_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Validate no missing values\n",
    "    missing_values = player_predictions.isnull().sum()\n",
    "    if missing_values.any():\n",
    "        logger.warning(f\"\\nMissing values found:\\n{missing_values[missing_values > 0]}\")\n",
    "        \n",
    "    logger.info(f\"Successfully merged {len(player_predictions)} player predictions\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error merging prediction data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:20,203 - INFO - Starting salary data cleaning process\n",
      "2025-01-21 23:20:20,270 - INFO - \n",
      "Status distribution:\n",
      "2025-01-21 23:20:20,272 - INFO - Status\n",
      "Estimate       871\n",
      "PRE-ARB        740\n",
      "UFA            423\n",
      "ARB 1          278\n",
      "ARB 3          213\n",
      "              ... \n",
      "$2,370,968       1\n",
      "$36,571,428      1\n",
      "$28,071,428      1\n",
      "$10,015,872      1\n",
      "$2,962,963       1\n",
      "Name: count, Length: 134, dtype: int64\n",
      "2025-01-21 23:20:20,276 - INFO - \n",
      "Salary cleaning summary:\n",
      "2025-01-21 23:20:20,298 - INFO - original_rows: 3821\n",
      "2025-01-21 23:20:20,299 - INFO - cleaned_rows: 3806\n",
      "2025-01-21 23:20:20,300 - INFO - valid_salary_rows: 2043\n",
      "2025-01-21 23:20:20,301 - INFO - min_salary: 250,000.00\n",
      "2025-01-21 23:20:20,302 - INFO - max_salary: 51,875,000.00\n",
      "2025-01-21 23:20:20,303 - INFO - mean_salary: 10,248,524.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of cleaned salary data:\n",
      "      Player Name    Year Team     Payroll   Status\n",
      "0  Corbin Carroll  2023.0  ari   1625000.0      NaN\n",
      "1  Corbin Carroll  2024.0  ari   3625000.0  Pre-Arb\n",
      "2  Corbin Carroll  2025.0  ari   5625000.0  Pre-Arb\n",
      "3  Corbin Carroll  2026.0  ari  10625000.0    ARB 1\n",
      "4  Corbin Carroll  2027.0  ari  12625000.0    ARB 2\n",
      "\n",
      "Data validation:\n",
      "Null values:\n",
      "Player Name       0\n",
      "Year              0\n",
      "Team              0\n",
      "Payroll        1763\n",
      "Status          407\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Salary Data Processing Module\n",
    "- Cleans and standardizes salary data\n",
    "- Preserves contract status information\n",
    "- Handles missing and invalid values\n",
    "- Validates data quality\n",
    "\"\"\"\n",
    "\n",
    "def clean_salary_data(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Clean and standardize salary data from Sportrac.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Raw salary data with Payroll and Status columns\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Cleaned salary data with standardized values\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting salary data cleaning process\")\n",
    "    \n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    try:\n",
    "        # Remove non-player rows (options, buyouts, etc)\n",
    "        cleaned_df = cleaned_df[~cleaned_df['Player Name'].str.contains(\n",
    "            'OPT-OUT|UFA|PLAYER OPT|CLUB OPT', \n",
    "            na=False, \n",
    "            case=False\n",
    "        )]\n",
    "        \n",
    "        # Clean Year column\n",
    "        cleaned_df['Year'] = pd.to_numeric(cleaned_df['Year'], errors='coerce')\n",
    "        cleaned_df = cleaned_df.dropna(subset=['Year'])\n",
    "        \n",
    "        # Clean Payroll column - two-step process\n",
    "        payroll = (cleaned_df['Payroll']\n",
    "                  .astype(str)\n",
    "                  .str.replace('$', '', regex=False)\n",
    "                  .str.replace(',', '', regex=False)\n",
    "                  .str.replace('-', '', regex=False))\n",
    "        \n",
    "        cleaned_df['Payroll'] = pd.to_numeric(payroll, errors='coerce')\n",
    "        \n",
    "        # Status validation and cleaning\n",
    "        if 'Status' not in cleaned_df.columns:\n",
    "            logger.warning(\"Status column missing from input data\")\n",
    "        else:\n",
    "            status_counts = cleaned_df['Status'].value_counts()\n",
    "            logger.info(\"\\nStatus distribution:\")\n",
    "            logger.info(status_counts)\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        stats = {\n",
    "            'original_rows': len(df),\n",
    "            'cleaned_rows': len(cleaned_df),\n",
    "            'valid_salary_rows': cleaned_df['Payroll'].notna().sum(),\n",
    "            'min_salary': cleaned_df['Payroll'].min(),\n",
    "            'max_salary': cleaned_df['Payroll'].max(),\n",
    "            'mean_salary': cleaned_df['Payroll'].mean()\n",
    "        }\n",
    "        \n",
    "        logger.info(\"\\nSalary cleaning summary:\")\n",
    "        for key, value in stats.items():\n",
    "            logger.info(f\"{key}: {value:,.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "            \n",
    "        return cleaned_df[['Player Name', 'Year', 'Team', 'Payroll', 'Status']].copy()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning salary data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Execute cleaning\n",
    "try:\n",
    "    salary_data_clean = clean_salary_data(salary_data)\n",
    "    \n",
    "    print(\"\\nSample of cleaned salary data:\")\n",
    "    print(salary_data_clean.head())\n",
    "    \n",
    "    print(\"\\nData validation:\")\n",
    "    print(f\"Null values:\\n{salary_data_clean.isnull().sum()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process salary data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def integrate_historical_data(sp_data: pd.DataFrame,\n",
    "                            rp_data: pd.DataFrame,\n",
    "                            batter_data: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Integrate historical stats with prediction data.\"\"\"\n",
    "    \n",
    "    # Load historical data\n",
    "    batting_history = pd.read_csv('../data/mlb_batting_data_2000_2024.csv')\n",
    "    pitching_history = pd.read_csv('../data/mlb_pitching_data_2000_2024.csv')\n",
    "    \n",
    "    # Drop rows missing Year/Season\n",
    "    batting_history = batting_history.dropna(subset=['Season'])\n",
    "    pitching_history = pitching_history.dropna(subset=['Season'])\n",
    "    \n",
    "    # Filter to prediction players and standardize columns\n",
    "    batter_ids = set(batter_data['IDfg'].unique())\n",
    "    sp_ids = set(sp_data['IDfg'].unique())\n",
    "    rp_ids = set(rp_data['IDfg'].unique())\n",
    "    \n",
    "    # Process batting data\n",
    "    batting_cols = list(set(batter_data.columns) & set(batting_history.columns))\n",
    "    batting_history = (batting_history[batting_history['IDfg'].isin(batter_ids)]\n",
    "                      .rename(columns={'Season': 'Year'})\n",
    "                      [batting_cols])\n",
    "    \n",
    "    # Process pitching data\n",
    "    pitching_cols = list(set(sp_data.columns) & set(pitching_history.columns))\n",
    "    sp_history = (pitching_history[pitching_history['IDfg'].isin(sp_ids)]\n",
    "                 .rename(columns={'Season': 'Year'})\n",
    "                 [pitching_cols])\n",
    "    rp_history = (pitching_history[pitching_history['IDfg'].isin(rp_ids)]\n",
    "                 .rename(columns={'Season': 'Year'})\n",
    "                 [pitching_cols])\n",
    "    \n",
    "    # Combine data\n",
    "    batter_data = pd.concat([batter_data, batting_history], ignore_index=True)\n",
    "    sp_data = pd.concat([sp_data, sp_history], ignore_index=True)\n",
    "    rp_data = pd.concat([rp_data, rp_history], ignore_index=True)\n",
    "    \n",
    "    # Sort and deduplicate\n",
    "    for df in [batter_data, sp_data, rp_data]:\n",
    "        df.sort_values(['IDfg', 'Year'], inplace=True)\n",
    "        df.drop_duplicates(subset=['IDfg', 'Year'], keep='first', inplace=True)\n",
    "        df.dropna(subset=['Year'], inplace=True)\n",
    "    \n",
    "    return batter_data, sp_data, rp_data\n",
    "\n",
    "# Update data with historical stats\n",
    "batter_data, sp_data, rp_data = integrate_historical_data(sp_data, rp_data, batter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP columns: ['Name', 'Season', 'Age', 'Role', 'IDfg', 'ERA', 'FIP', 'SIERA', 'K%', 'BB%', 'HR/9', 'SwStr%', 'Contact%', 'O-Swing%', 'Z-Contact%', 'F-Strike%', 'Zone%', 'CSW%', 'CStr%', 'GB%', 'FB%', 'IFFB%', 'HR/FB', 'Soft%', 'Med%', 'Hard%', 'FBv', 'IP', 'GS', 'G', 'WAR', 'prediction_year', 'position_group', 'Position']\n",
      "RP columns: ['Name', 'Season', 'Age', 'Role', 'IDfg', 'ERA', 'FIP', 'SIERA', 'K%', 'BB%', 'HR/9', 'SwStr%', 'Contact%', 'O-Swing%', 'Z-Contact%', 'F-Strike%', 'Zone%', 'CSW%', 'CStr%', 'GB%', 'FB%', 'IFFB%', 'HR/FB', 'Soft%', 'Med%', 'Hard%', 'FBv', 'IP', 'GS', 'G', 'WAR', 'prediction_year', 'position_group', 'Position']\n",
      "Batter columns: ['Name', 'Age', 'Year', 'IDfg', 'BB%', 'K%', 'BABIP', 'AVG', 'OBP', 'SLG', 'wOBA', 'wRC+', 'def_value', 'Position', 'BsR', 'wSB', 'UBR', 'wGDP', 'SB', 'CS', 'Off', 'Def', 'WAR', 'PA', 'G', 'HR', '2B', '3B', 'RBI', 'R', 'prediction_year', 'position_group']\n"
     ]
    }
   ],
   "source": [
    "print(\"SP columns:\", sp_data.columns.tolist())\n",
    "print(\"RP columns:\", rp_data.columns.tolist())\n",
    "print(\"Batter columns:\", batter_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:21,176 - INFO - \n",
      "Merge Results:\n",
      "2025-01-21 23:20:21,178 - INFO - Total rows in player_ref: 17004\n",
      "2025-01-21 23:20:21,179 - INFO - Total rows in salary_data: 3806\n",
      "2025-01-21 23:20:21,180 - INFO - Matched rows: 2566\n",
      "2025-01-21 23:20:21,182 - INFO - Rows with payroll: 1284\n",
      "2025-01-21 23:20:21,184 - INFO - Rows with status: 2297\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Player Reference and ID Integration with Enhanced Name Matching\n",
    "Handles UTF-8 encoding and accent normalization\n",
    "\"\"\"\n",
    "\n",
    "import unidecode\n",
    "from thefuzz import fuzz\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    \"\"\"Normalize player names by removing accents and standardizing format.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    return unidecode.unidecode(str(name)).upper().strip()\n",
    "\n",
    "# First standardize pitcher dataframes\n",
    "sp_data = sp_data.rename(columns={'Season': 'Year'})\n",
    "rp_data = rp_data.rename(columns={'Season': 'Year'})\n",
    "\n",
    "def create_player_reference(sp_df: pd.DataFrame, \n",
    "                          rp_df: pd.DataFrame, \n",
    "                          batter_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create unified player reference with normalized names.\"\"\"\n",
    "    player_ref = pd.concat([\n",
    "        sp_df[['Name', 'IDfg', 'position_group', 'Year']],\n",
    "        rp_df[['Name', 'IDfg', 'position_group', 'Year']],\n",
    "        batter_df[['Name', 'IDfg', 'position_group', 'Year']]\n",
    "    ])\n",
    "    \n",
    "    player_ref['Name_Normalized'] = player_ref['Name'].apply(normalize_name)\n",
    "    return player_ref\n",
    "\n",
    "def merge_salary_with_ids(salary_df: pd.DataFrame, player_ref: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge salary data with player reference, maintaining year-specific matches.\"\"\"\n",
    "    \n",
    "    # Normalize salary data names\n",
    "    salary_df['Name_Normalized'] = salary_df['Player Name'].apply(normalize_name)\n",
    "    \n",
    "    # Merge on both name and year\n",
    "    merged_df = player_ref.merge(\n",
    "        salary_df[['Name_Normalized', 'Year', 'Team', 'Payroll', 'Status']],\n",
    "        on=['Name_Normalized', 'Year'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Keep only rows that have either Payroll or Status\n",
    "    valid_data = merged_df[merged_df['Payroll'].notna() | merged_df['Status'].notna()]\n",
    "    \n",
    "    # Log merge statistics\n",
    "    logger.info(f\"\\nMerge Results:\")\n",
    "    logger.info(f\"Total rows in player_ref: {len(player_ref)}\")\n",
    "    logger.info(f\"Total rows in salary_data: {len(salary_df)}\")\n",
    "    logger.info(f\"Matched rows: {len(valid_data)}\")\n",
    "    logger.info(f\"Rows with payroll: {valid_data['Payroll'].notna().sum()}\")\n",
    "    logger.info(f\"Rows with status: {valid_data['Status'].notna().sum()}\")\n",
    "    \n",
    "    return valid_data.drop('Name_Normalized', axis=1)\n",
    "\n",
    "try:\n",
    "    player_ref = create_player_reference(sp_data, rp_data, batter_data)\n",
    "    salary_data_with_id = merge_salary_with_ids(salary_data_clean, player_ref)\n",
    "    \n",
    "    # Display unmatched players\n",
    "    unmatched = salary_data_with_id[salary_data_with_id['IDfg'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"\\nSample unmatched players:\")\n",
    "        print(unmatched['Player Name'].unique()[:10])\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in ID integration: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:23,105 - INFO - \n",
      "Status distribution after normalization:\n",
      "2025-01-21 23:20:23,106 - INFO - Pre-Arb: 717\n",
      "2025-01-21 23:20:23,107 - INFO - Signed: 505\n",
      "2025-01-21 23:20:23,108 - INFO - Free Agent: 409\n",
      "2025-01-21 23:20:23,109 - INFO - Arb-1: 302\n",
      "2025-01-21 23:20:23,110 - INFO - Arb-3: 225\n",
      "2025-01-21 23:20:23,112 - INFO - Arb-2: 164\n",
      "2025-01-21 23:20:23,112 - INFO - Team Option: 92\n",
      "2025-01-21 23:20:23,113 - INFO - Arb-4: 54\n",
      "2025-01-21 23:20:23,114 - INFO - Arb-1 (Super 2): 40\n",
      "2025-01-21 23:20:23,114 - INFO - Player Option: 18\n",
      "2025-01-21 23:20:23,115 - INFO - Opt-Out: 18\n",
      "2025-01-21 23:20:23,115 - INFO - Vesting Option: 11\n",
      "2025-01-21 23:20:23,116 - INFO - Mutual Option: 10\n",
      "2025-01-21 23:20:23,117 - INFO - Unknown: 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Contract Status Processing Module\n",
    "- Determines Free Agency years for all players\n",
    "- Handles arbitration progression\n",
    "- Processes contract options and UFA designations\n",
    "- Validates contract timelines\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Contract Status Processing with IDfg\n",
    "Determines FA years based on latest available status\n",
    "\"\"\"\n",
    "\n",
    "def normalize_contract_status(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize MLB player contract statuses into standardized format.\n",
    "    \n",
    "    Process:\n",
    "    1. Sort by player and year\n",
    "    2. Check for long-term contracts\n",
    "    3. Process status patterns in priority order\n",
    "    4. Handle special cases (Estimate, Arb Avoided)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame must contain:\n",
    "            - IDfg: Player ID\n",
    "            - Year: Contract year\n",
    "            - Status: Raw contract status\n",
    "            - Payroll: Salary information\n",
    "            \n",
    "    Returns:\n",
    "        DataFrame: Original DataFrame with new 'Normalized_Status' column\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    result_df = result_df.sort_values(['IDfg', 'Year'])\n",
    "    \n",
    "    def has_long_term_contract(group):\n",
    "        \"\"\"Check if player has signed contract years\"\"\"\n",
    "        # First check: Any future years with payroll but no status\n",
    "        future_signed = group[\n",
    "            (group['Payroll'].notna()) & \n",
    "            (group['Status'].isna())\n",
    "        ]\n",
    "        if len(future_signed) > 0:\n",
    "            return True\n",
    "            \n",
    "        # Second check: Signed years beyond arb\n",
    "        arb_years = group[group['Status'].str.contains('ARB', na=False, case=True)]\n",
    "        if len(arb_years) > 0:\n",
    "            last_arb_year = arb_years['Year'].max()\n",
    "            future_signed = group[\n",
    "                (group['Year'] > last_arb_year) & \n",
    "                (group['Payroll'].notna()) & \n",
    "                (group['Status'].isna())\n",
    "            ]\n",
    "            return len(future_signed) > 0\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def get_next_year_status(group):\n",
    "        \"\"\"Look ahead one year to determine current status for 'Estimate'\"\"\"\n",
    "        group = group.copy()\n",
    "        group['Next_Status'] = group['Status'].shift(-1)\n",
    "        group['Has_Long_Contract'] = has_long_term_contract(group)\n",
    "        return group\n",
    "    \n",
    "    def _normalize_single_status(row):\n",
    "        \"\"\"Normalize individual status values.\"\"\"\n",
    "        if pd.isna(row['Status']):\n",
    "            if pd.notna(row['Payroll']) and row.get('Has_Long_Contract', False):\n",
    "                return 'Signed'\n",
    "            return 'Free Agent'\n",
    "            \n",
    "        status = str(row['Status']).upper().strip()\n",
    "        if status == '-' and pd.notna(row['Payroll']):\n",
    "            return 'Signed'\n",
    "        # Handle dollar amounts\n",
    "        if status.startswith('$'):\n",
    "            return 'Signed'\n",
    "            \n",
    "        # Handle options\n",
    "        if 'PLAYER' in status:\n",
    "            return 'Player Option'\n",
    "        if 'CLUB' in status:\n",
    "            return 'Team Option'\n",
    "        if 'MUTUAL' in status:\n",
    "            return 'Mutual Option'\n",
    "        if 'VESTING' in status:\n",
    "            return 'Vesting Option'\n",
    "        if 'OPT-OUT' in status:\n",
    "            return 'Opt-Out'\n",
    "            \n",
    "        # Handle 'Estimate' based on next year's status\n",
    "        if status == 'ESTIMATE':\n",
    "            next_status = str(row['Next_Status']).upper().strip() if pd.notna(row['Next_Status']) else ''\n",
    "            if any(x in next_status for x in ['UFA', 'FA']):\n",
    "                return 'Arb-3'\n",
    "            if 'ARB 1' in next_status:\n",
    "                return 'Pre-Arb'\n",
    "            if 'ARB 2' in next_status:\n",
    "                return 'Arb-1'\n",
    "            if 'ARB 3' in next_status:\n",
    "                return 'Arb-2'\n",
    "            if 'ARB 4' in next_status:\n",
    "                return 'Arb-3'\n",
    "            return 'Pre-Arb'\n",
    "            \n",
    "        # Handle 'Arb Avoided' - keep as arb status\n",
    "        if 'AVOIDED' in status or 'BYPASSED' in status:\n",
    "            next_status = str(row['Next_Status']).upper().strip() if pd.notna(row['Next_Status']) else ''\n",
    "            if 'ARB 2' in next_status:\n",
    "                return 'Arb-1'\n",
    "            if 'ARB 3' in next_status:\n",
    "                return 'Arb-2'\n",
    "            if 'ARB 4' in next_status:\n",
    "                return 'Arb-3'\n",
    "            if pd.isna(row['Next_Status']):\n",
    "                return 'Signed'\n",
    "            return 'Arb-1'  # Default if can't determine\n",
    "            \n",
    "        # Handle regular arbitration\n",
    "        if 'ARB' in status:\n",
    "            if 'S2' in status:\n",
    "                return 'Arb-1 (Super 2)'\n",
    "            if 'ARB 4' in status:\n",
    "                return 'Arb-4'\n",
    "            if 'ARB 3' in status:\n",
    "                return 'Arb-3'\n",
    "            if 'ARB 2' in status:\n",
    "                return 'Arb-2'\n",
    "            if 'ARB 1' in status:\n",
    "                return 'Arb-1'\n",
    "                \n",
    "        # Handle pre-arbitration\n",
    "        if 'PRE' in status and 'ARB' in status:\n",
    "            return 'Pre-Arb'\n",
    "            \n",
    "        # Handle free agency\n",
    "        if any(x in status for x in ['UFA', 'RFA', 'FA', 'FREE AGENT']):\n",
    "            return 'Free Agent'\n",
    "            \n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Process by player group\n",
    "    result_df = result_df.groupby('IDfg', group_keys=False).apply(get_next_year_status)\n",
    "    \n",
    "    # Apply normalization\n",
    "    result_df['Normalized_Status'] = result_df.apply(_normalize_single_status, axis=1)\n",
    "    \n",
    "    # Log distribution\n",
    "    status_counts = result_df['Normalized_Status'].value_counts()\n",
    "    logger.info(\"\\nStatus distribution after normalization:\")\n",
    "    for status, count in status_counts.items():\n",
    "        logger.info(f\"{status}: {count}\")\n",
    "        \n",
    "    return result_df.drop(['Next_Status', 'Has_Long_Contract'], axis=1)\n",
    "\n",
    "try:\n",
    "    contract_data = normalize_contract_status(salary_data_with_id)\n",
    "    \n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process contract statuses: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:24,794 - INFO - Generated 3794 timeline records\n"
     ]
    }
   ],
   "source": [
    "def generate_contract_timeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate complete contract timeline for each player.\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    def process_player_timeline(group):\n",
    "        player_rows = group.copy()\n",
    "        \n",
    "        # Check for Super 2\n",
    "        is_super2 = any('Super 2' in str(status) for status in player_rows['Normalized_Status'])\n",
    "        \n",
    "        # Get latest year and status\n",
    "        latest_year = player_rows['Year'].max()\n",
    "        latest_status_series = player_rows.loc[player_rows['Year'] == latest_year, 'Normalized_Status']\n",
    "        \n",
    "        if len(latest_status_series) == 0:\n",
    "            logger.warning(f\"No status found for player {player_rows['IDfg'].iloc[0]} in year {latest_year}\")\n",
    "            return player_rows\n",
    "            \n",
    "        latest_status = latest_status_series.iloc[0]\n",
    "        new_rows = []\n",
    "        \n",
    "        if latest_status == 'Free Agent':\n",
    "            return player_rows\n",
    "            \n",
    "        # Modified status checking\n",
    "        if latest_status.startswith('Arb-4'):\n",
    "            new_rows.append({'Year': latest_year + 1, 'Normalized_Status': 'Free Agent'})\n",
    "            \n",
    "        elif latest_status.startswith('Arb-3'):\n",
    "            if is_super2:\n",
    "                new_rows.append({'Year': latest_year + 1, 'Normalized_Status': 'Arb-4'})\n",
    "                new_rows.append({'Year': latest_year + 2, 'Normalized_Status': 'Free Agent'})\n",
    "            else:\n",
    "                new_rows.append({'Year': latest_year + 1, 'Normalized_Status': 'Free Agent'})\n",
    "                \n",
    "        elif latest_status.startswith('Arb-2'):\n",
    "            new_rows.append({'Year': latest_year + 1, 'Normalized_Status': 'Arb-3'})\n",
    "            if is_super2:\n",
    "                new_rows.append({'Year': latest_year + 2, 'Normalized_Status': 'Arb-4'})\n",
    "                new_rows.append({'Year': latest_year + 3, 'Normalized_Status': 'Free Agent'})\n",
    "            else:\n",
    "                new_rows.append({'Year': latest_year + 2, 'Normalized_Status': 'Free Agent'})\n",
    "                \n",
    "        elif latest_status.startswith('Arb-1'):\n",
    "            arb2_status = 'Arb-2'\n",
    "            new_rows.append({'Year': latest_year + 1, 'Normalized_Status': arb2_status})\n",
    "            new_rows.append({'Year': latest_year + 2, 'Normalized_Status': 'Arb-3'})\n",
    "            if is_super2:\n",
    "                new_rows.append({'Year': latest_year + 3, 'Normalized_Status': 'Arb-4'})\n",
    "                new_rows.append({'Year': latest_year + 4, 'Normalized_Status': 'Free Agent'})\n",
    "            else:\n",
    "                new_rows.append({'Year': latest_year + 3, 'Normalized_Status': 'Free Agent'})\n",
    "                \n",
    "        elif latest_status == 'Pre-Arb':\n",
    "            pre_arb_years = len(player_rows[player_rows['Normalized_Status'] == 'Pre-Arb'])\n",
    "            remaining_pre_arb = 3 - pre_arb_years\n",
    "            \n",
    "            current_year = latest_year\n",
    "            for i in range(remaining_pre_arb):\n",
    "                current_year += 1\n",
    "                new_rows.append({'Year': current_year, 'Normalized_Status': 'Pre-Arb'})\n",
    "            \n",
    "            arb1_status = 'Arb-1 (Super 2)' if is_super2 else 'Arb-1'\n",
    "            new_rows.append({'Year': current_year + 1, 'Normalized_Status': arb1_status})\n",
    "            new_rows.append({'Year': current_year + 2, 'Normalized_Status': 'Arb-2'})\n",
    "            new_rows.append({'Year': current_year + 3, 'Normalized_Status': 'Arb-3'})\n",
    "            \n",
    "            if is_super2:\n",
    "                new_rows.append({'Year': current_year + 4, 'Normalized_Status': 'Arb-4'})\n",
    "                new_rows.append({'Year': current_year + 5, 'Normalized_Status': 'Free Agent'})\n",
    "            else:\n",
    "                new_rows.append({'Year': current_year + 4, 'Normalized_Status': 'Free Agent'})\n",
    "        \n",
    "        # Add new rows to player timeline\n",
    "        if new_rows:\n",
    "            for row in new_rows:\n",
    "                row.update({col: group.iloc[0][col] for col in group.columns \n",
    "                        if col not in ['Year', 'Normalized_Status', 'Status', 'Payroll']})\n",
    "            return pd.concat([player_rows, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "        \n",
    "        return player_rows\n",
    "    \n",
    "    # Process each player\n",
    "    result_df = result_df.groupby('IDfg', group_keys=False).apply(process_player_timeline)\n",
    "    \n",
    "    return result_df.sort_values(['IDfg', 'Year']).reset_index(drop=True)\n",
    "\n",
    "# Execute timeline generation\n",
    "try:\n",
    "    contract_timeline = generate_contract_timeline(contract_data)\n",
    "    logger.info(f\"Generated {len(contract_timeline)} timeline records\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Timeline generation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:25,042 - WARNING - Found 4 players missing FA status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Players missing Free Agent status:\n",
      "    IDfg            Player Last Status  Last Year\n",
      "0  12791     Michael Kelly     Unknown       2025\n",
      "1  15274     Mike Tauchman      Signed       2025\n",
      "2  19600  Bryan De La Cruz      Signed       2025\n",
      "3  20123         Juan Soto      Signed       2039\n"
     ]
    }
   ],
   "source": [
    "# Validate all players have FA year\n",
    "try:\n",
    "    # Group by IDfg and check if any player is missing FA status\n",
    "    missing_fa = []\n",
    "    for idfg, group in contract_timeline.groupby('IDfg'):\n",
    "        if not any(group['Normalized_Status'] == 'Free Agent'):\n",
    "            player_name = group['Name'].iloc[0]\n",
    "            last_status = group.sort_values('Year')['Normalized_Status'].iloc[-1]\n",
    "            missing_fa.append({\n",
    "                'IDfg': idfg,\n",
    "                'Player': player_name,\n",
    "                'Last Status': last_status,\n",
    "                'Last Year': group['Year'].max()\n",
    "            })\n",
    "    \n",
    "    if missing_fa:\n",
    "        print(\"\\nPlayers missing Free Agent status:\")\n",
    "        missing_fa_df = pd.DataFrame(missing_fa)\n",
    "        print(missing_fa_df.to_string())\n",
    "        logger.warning(f\"Found {len(missing_fa)} players missing FA status\")\n",
    "    else:\n",
    "        logger.info(\"All players have Free Agent status\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"FA validation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_fa_timeline(timeline_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extend timeline beyond first FA year through 2039.\"\"\"\n",
    "    \n",
    "    # Find first FA year for each player\n",
    "    fa_years = (timeline_df[timeline_df['Normalized_Status'] == 'Free Agent']\n",
    "                .groupby('IDfg')['Year']\n",
    "                .min()\n",
    "                .reset_index())\n",
    "    \n",
    "    # Generate future FA rows\n",
    "    future_rows = []\n",
    "    for _, row in fa_years.iterrows():\n",
    "        idfg = row['IDfg']\n",
    "        start_year = int(row['Year']) + 1\n",
    "        player_info = timeline_df[timeline_df['IDfg'] == idfg].iloc[0]\n",
    "        \n",
    "        for year in range(start_year, 2040):\n",
    "            future_rows.append({\n",
    "                'Name': player_info['Name'],\n",
    "                'IDfg': idfg,\n",
    "                'position_group': player_info['position_group'],\n",
    "                'Year': year,\n",
    "                'Team': np.nan,\n",
    "                'Payroll': np.nan,\n",
    "                'Status': np.nan,\n",
    "                'Normalized_Status': 'Free Agent'\n",
    "            })\n",
    "    \n",
    "    # Add new rows to timeline\n",
    "    extended_timeline = pd.concat([\n",
    "        timeline_df,\n",
    "        pd.DataFrame(future_rows)\n",
    "    ])\n",
    "    \n",
    "    # Sort and deduplicate\n",
    "    extended_timeline = (extended_timeline\n",
    "                       .sort_values(['IDfg', 'Year'])\n",
    "                       .drop_duplicates(subset=['IDfg', 'Year'], keep='first'))\n",
    "    \n",
    "    return extended_timeline\n",
    "extended_timeline=extend_fa_timeline(contract_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:25,786 - INFO - Processed 11493 rows\n",
      "2025-01-21 23:20:25,787 - INFO - Average WAR value: $8,731,306.66\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WAR Value Calculation Module\n",
    "Applies tiered WAR values and inflation adjustments\n",
    "\"\"\"\n",
    "\n",
    "# Constants\n",
    "WAR_VALUE_TIERS = {\n",
    "    'tier1': {'max': 2, 'value': 8_000_000},\n",
    "    'tier2': {'max': 4, 'value': 9_000_000},\n",
    "    'tier3': {'value': 10_000_000}\n",
    "}\n",
    "INFLATION_RATE = 0.04\n",
    "BASE_YEAR = 2025\n",
    "\n",
    "def calculate_inflation_multiplier(year: int) -> float:\n",
    "    \"\"\"Calculate inflation multiplier from base year.\"\"\"\n",
    "    return (1 + INFLATION_RATE) ** (year - BASE_YEAR)\n",
    "\n",
    "def calculate_war_value(war: float, year: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate WAR value using tiered system and inflation.\n",
    "    \n",
    "    Args:\n",
    "        war (float): WAR value\n",
    "        year (int): Year for inflation adjustment\n",
    "    \"\"\"\n",
    "    if pd.isna(war) or war <= 0:\n",
    "        return 0.0\n",
    "        \n",
    "    value = 0.0\n",
    "    remaining_war = war\n",
    "    \n",
    "    # Tier 1: 0-2 WAR\n",
    "    tier1_war = min(remaining_war, WAR_VALUE_TIERS['tier1']['max'])\n",
    "    value += tier1_war * WAR_VALUE_TIERS['tier1']['value']\n",
    "    remaining_war -= tier1_war\n",
    "    \n",
    "    if remaining_war <= 0:\n",
    "        return value * calculate_inflation_multiplier(year)\n",
    "        \n",
    "    # Tier 2: 2-4 WAR\n",
    "    tier2_war = min(remaining_war, WAR_VALUE_TIERS['tier2']['max'] - WAR_VALUE_TIERS['tier1']['max'])\n",
    "    value += tier2_war * WAR_VALUE_TIERS['tier2']['value']\n",
    "    remaining_war -= tier2_war\n",
    "    \n",
    "    if remaining_war <= 0:\n",
    "        return value * calculate_inflation_multiplier(year)\n",
    "        \n",
    "    # Tier 3: 4+ WAR\n",
    "    value += remaining_war * WAR_VALUE_TIERS['tier3']['value']\n",
    "    \n",
    "    return value * calculate_inflation_multiplier(year)\n",
    "\n",
    "try:\n",
    "    # Join predictions with timeline\n",
    "    timeline_with_war = extended_timeline.merge(\n",
    "        player_predictions[['IDfg', 'prediction_year', 'WAR']],\n",
    "        left_on=['IDfg', 'Year'],\n",
    "        right_on=['IDfg', 'prediction_year'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate WAR values\n",
    "    timeline_with_war['Base_Value'] = timeline_with_war.apply(\n",
    "        lambda x: calculate_war_value(x['WAR'], x['Year']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Clean up and validate\n",
    "    timeline_with_war = timeline_with_war.drop('prediction_year', axis=1)\n",
    "    \n",
    "    logger.info(f\"Processed {len(timeline_with_war)} rows\")\n",
    "    logger.info(f\"Average WAR value: ${timeline_with_war['Base_Value'].mean():,.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to calculate WAR values: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:28,621 - INFO - Processed 11493 rows\n",
      "2025-01-21 23:20:28,622 - INFO - Average contract value: $7,285,880.64\n",
      "2025-01-21 23:20:28,624 - INFO - Processed 11493 rows\n",
      "2025-01-21 23:20:28,625 - INFO - Contract values calculated: 3032\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Contract Value Calculator\n",
    "Determines player contract values based on:\n",
    "1. Existing payroll data (if available)\n",
    "2. Contract status (Pre-ARB, ARB1-3, FA)\n",
    "3. WAR-based market value\n",
    "\"\"\"\n",
    "\n",
    "MIN_SALARY = {\n",
    "    'Pre-Arb': 720000,\n",
    "    'Arb-1': 1000000,\n",
    "    'Arb-1 (Super 2)': 1200000,  # Higher floor for Super 2\n",
    "    'Arb-2': 2500000,\n",
    "    'Arb-3': 4000000,\n",
    "    'Arb-4': 5000000\n",
    "}\n",
    "ARB_PERCENT = {\n",
    "    'Arb-1': 0.25,\n",
    "    'Arb-1 (Super 2)': 0.25,\n",
    "    'Arb-2': 0.33,\n",
    "    'Arb-3': 0.50,\n",
    "    'Arb-4': 0.65\n",
    "}\n",
    "\n",
    "def calculate_contract_value(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculate contract values ensuring arbitration values never decrease.\"\"\"\n",
    "    \n",
    "    # Create copy to avoid modifying original\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Sort by player and year for tracking\n",
    "    result = result.sort_values(['IDfg', 'Year'])\n",
    "    \n",
    "    # Initialize contract value column\n",
    "    result['contract_value'] = np.nan\n",
    "    \n",
    "    # Process each player separately\n",
    "    for player_id in result['IDfg'].unique():\n",
    "        player_mask = result['IDfg'] == player_id\n",
    "        player_data = result[player_mask].copy()\n",
    "        \n",
    "        prev_value = 0\n",
    "        for idx, row in player_data.iterrows():\n",
    "            current_value = row['Base_Value']\n",
    "            status = row['Normalized_Status']\n",
    "\n",
    "            # Handle existing payroll data first\n",
    "            if pd.notna(row['Payroll']):\n",
    "                contract_value = float(row['Payroll'])\n",
    "            \n",
    "            # Pre-Arb cases\n",
    "            elif status == 'Pre-Arb':\n",
    "                contract_value = max(MIN_SALARY['Pre-Arb'], prev_value)\n",
    "            \n",
    "            # Handle different arbitration years\n",
    "            elif status in ARB_PERCENT:\n",
    "                min_salary = MIN_SALARY.get(status, MIN_SALARY['Arb-1'])\n",
    "                arb_pct = ARB_PERCENT[status]\n",
    "                contract_value = max(\n",
    "                    min_salary,\n",
    "                    current_value * arb_pct,\n",
    "                    prev_value\n",
    "                )\n",
    "            \n",
    "            # Free Agent or other status\n",
    "            else:\n",
    "                contract_value = None\n",
    "            \n",
    "            # Update the value in the result dataframe\n",
    "            result.loc[idx, 'contract_value'] = contract_value\n",
    "            \n",
    "            # Update previous value if we have a valid contract value\n",
    "            if pd.notna(contract_value):\n",
    "                prev_value = contract_value\n",
    "    \n",
    "    # Calculate average (excluding NaN values)\n",
    "    valid_contracts = result['contract_value'].dropna()\n",
    "    if len(valid_contracts) > 0:\n",
    "        logger.info(f\"Processed {len(result)} rows\")\n",
    "        logger.info(f\"Average contract value: ${valid_contracts.mean():,.2f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "try:\n",
    "    # Calculate contract values\n",
    "    timeline_with_values = calculate_contract_value(timeline_with_war)\n",
    "    \n",
    "    # Validate results\n",
    "    valid_contracts = timeline_with_values['contract_value'].notna().sum()\n",
    "    logger.info(f\"Processed {len(timeline_with_values)} rows\")\n",
    "    logger.info(f\"Contract values calculated: {valid_contracts}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to calculate contract values: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:28,656 - INFO - Calculated 3032 surplus values\n",
      "2025-01-21 23:20:28,657 - INFO - Average surplus value: $5,237,738.84\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate Surplus Value\n",
    "Surplus = Base Value - Contract Value\n",
    "Only calculated for rows with existing contract values\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Verify contract_value exists\n",
    "    if 'contract_value' not in timeline_with_values.columns:\n",
    "        raise ValueError(\"contract_value column not found in dataframe\")\n",
    "        \n",
    "    # Calculate surplus value only where contract_value exists\n",
    "    timeline_with_values['surplus_value'] = np.where(\n",
    "        timeline_with_values['contract_value'].notna(),\n",
    "        timeline_with_values['Base_Value'] - timeline_with_values['contract_value'],\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    # Validate results\n",
    "    valid_surplus = timeline_with_values['surplus_value'].notna().sum()\n",
    "    avg_surplus = timeline_with_values['surplus_value'].mean()\n",
    "    \n",
    "    logger.info(f\"Calculated {valid_surplus} surplus values\")\n",
    "    logger.info(f\"Average surplus value: ${avg_surplus:,.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to calculate surplus values: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:31,132 - INFO - Added historical records. New shape: (14872, 39)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Integrate Historical Data (2002-2024)\n",
    "Add historical stats for players in prediction set\n",
    "\"\"\"\n",
    "HISTORICAL_WAR_VALUE = {\n",
    "    2002: 4800000,  # backfilled with 2005 value\n",
    "    2003: 4800000,  # backfilled with 2005 value\n",
    "    2004: 4800000,  # backfilled with 2005 value\n",
    "    2005: 4800000,\n",
    "    2006: 5200000,  # interpolated\n",
    "    2007: 5700000,\n",
    "    2008: 6200000,\n",
    "    2009: 6400000,\n",
    "    2010: 6000000,\n",
    "    2011: 7500000,\n",
    "    2012: 6500000,\n",
    "    2013: 7400000,\n",
    "    2014: 7600000,\n",
    "    2015: 8000000,\n",
    "    2016: 8000000,\n",
    "    2017: 7900000,\n",
    "    2018: 8000000,\n",
    "    2019: 8100000,\n",
    "    2020: 7900000,\n",
    "    2021: 8100000,\n",
    "    2022: 8200000,\n",
    "    2023: 8100000,\n",
    "    2024: 8200000  # current value\n",
    "}\n",
    "\n",
    "# Default value for future years\n",
    "WAR_VALUE = 8200000\n",
    "\n",
    "def get_war_value(year: int) -> float:\n",
    "    \"\"\"Get WAR value for specific year, default to current WAR_VALUE if not found.\"\"\"\n",
    "    return HISTORICAL_WAR_VALUE.get(year, WAR_VALUE)\n",
    "\n",
    "def integrate_historical_stats(timeline_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add historical stats (2002-2024) for prediction players.\"\"\"\n",
    "    \n",
    "    # Load historical data\n",
    "    batting_history = pd.read_csv('../data/mlb_batting_data_2000_2024.csv')\n",
    "    pitching_history = pd.read_csv('../data/mlb_pitching_data_2000_2024.csv')\n",
    "    \n",
    "    # Get current players info\n",
    "    current_players = (timeline_df[['IDfg', 'Name', 'position_group']]\n",
    "                      .drop_duplicates(subset=['IDfg']))\n",
    "    \n",
    "    # Format batting data\n",
    "    batter_cols = ['IDfg', 'Season', 'Name', 'Team', 'WAR', 'BB%', 'K%', 'AVG', \n",
    "                   'OBP', 'SLG', 'OPS', 'wOBA', 'wRC+', 'Off', 'BsR', 'Def', 'Age', 'HR', '2B', '3B', 'R', 'RBI', 'SB', 'CS']\n",
    "    batting_history = (batting_history[batting_history['IDfg'].isin(current_players['IDfg'])]\n",
    "                      [batter_cols]\n",
    "                      .rename(columns={'Season': 'Year', 'WAR': 'WAR_batter', \n",
    "                                     'BB%': 'BB%_bat', 'K%': 'K%_bat'}))\n",
    "    \n",
    "    # Format pitching data\n",
    "    pitcher_cols = ['IDfg', 'Season', 'Name', 'Team', 'WAR', 'ERA', 'FIP', 'SIERA',\n",
    "                    'K%', 'BB%', 'Age']\n",
    "    pitching_history = (pitching_history[pitching_history['IDfg'].isin(current_players['IDfg'])]\n",
    "                       [pitcher_cols]\n",
    "                       .rename(columns={'Season': 'Year', 'WAR': 'WAR_pitcher',\n",
    "                                      'K%': 'K%_pit', 'BB%': 'BB%_pit'}))\n",
    "    \n",
    "    # Merge batting and pitching data\n",
    "    historical = (batting_history.merge(pitching_history, \n",
    "                                      on=['IDfg', 'Year', 'Name', 'Team', 'Age'],\n",
    "                                      how='outer'))\n",
    "    \n",
    "    # Add position info from current data\n",
    "    historical = historical.merge(current_players[['IDfg', 'position_group']], \n",
    "                                on='IDfg')\n",
    "    \n",
    "    # Fill NaN WAR values with 0\n",
    "    historical['WAR_batter'] = historical['WAR_batter'].fillna(0)\n",
    "    historical['WAR_pitcher'] = historical['WAR_pitcher'].fillna(0)\n",
    "    \n",
    "    # Calculate total WAR\n",
    "    historical['WAR'] = historical['WAR_batter'] + historical['WAR_pitcher']\n",
    "    \n",
    "    # Add status columns\n",
    "    historical['Status'] = 'NA'\n",
    "    historical['Normalized_Status'] = 'NA'\n",
    "    historical['Payroll'] = np.nan\n",
    "    \n",
    "    # Calculate base value\n",
    "    historical['Base_Value'] = historical.apply(\n",
    "        lambda x: x['WAR'] * get_war_value(int(x['Year'])), axis=1\n",
    "    )\n",
    "    historical['Contract_Value'] = np.nan\n",
    "    historical['surplus_value'] = np.nan\n",
    "    \n",
    "    # Combine with timeline\n",
    "    complete_timeline = pd.concat([timeline_df, historical])\n",
    "    \n",
    "    # Sort and remove duplicates\n",
    "    complete_timeline = (complete_timeline\n",
    "                       .sort_values(['IDfg', 'Year'])\n",
    "                       .drop_duplicates(subset=['IDfg', 'Year']))\n",
    "    \n",
    "    return complete_timeline\n",
    "\n",
    "try:\n",
    "    timeline_with_history = integrate_historical_stats(timeline_with_values)\n",
    "    logger.info(f\"Added historical records. New shape: {timeline_with_history.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to integrate historical data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 two-way players\n",
      "Records processed: 14872\n",
      "Columns: ['Name', 'IDfg', 'position_group', 'Year', 'Team', 'Payroll', 'Status', 'Normalized_Status', 'WAR', 'Base_Value', 'contract_value', 'surplus_value', 'WAR_batter', 'BB%_bat', 'K%_bat', 'AVG', 'OBP', 'SLG', 'OPS', 'wOBA', 'wRC+', 'Off', 'BsR', 'Def', 'Age', 'HR', '2B', '3B', 'R', 'RBI', 'SB', 'CS', 'WAR_pitcher', 'ERA', 'FIP', 'SIERA', 'K%_pit', 'BB%_pit', 'Contract_Value', 'Two_Way', 'Position']\n"
     ]
    }
   ],
   "source": [
    "def integrate_player_statistics(value_data, batter_data, sp_data, rp_data):\n",
    "    \"\"\"Integrate stats with combined positions for two-way players\"\"\"\n",
    "    \n",
    "    # Split data\n",
    "    historical_data = value_data[value_data['Year'] < 2025].copy()\n",
    "    prediction_data = value_data[value_data['Year'] >= 2025].copy()\n",
    "    \n",
    "    # Clean prediction data - keep only essential columns\n",
    "    essential_cols = ['Name', 'IDfg', 'position_group', 'Year', 'Team', \n",
    "                     'Payroll', 'Status', 'Normalized_Status', 'WAR', 'Base_Value',\n",
    "                     'contract_value', 'surplus_value']\n",
    "    prediction_data = prediction_data[essential_cols].copy()\n",
    "    \n",
    "    \n",
    "    # Find two-way players\n",
    "    batter_ids = set(batter_data['IDfg'].unique())\n",
    "    pitcher_ids = set(sp_data['IDfg'].unique()) | set(rp_data['IDfg'].unique())\n",
    "    two_way_players = batter_ids.intersection(pitcher_ids)\n",
    "    print(f\"Found {len(two_way_players)} two-way players\")\n",
    "    \n",
    "    # Add two-way flag\n",
    "    prediction_data['Two_Way'] = prediction_data['IDfg'].isin(two_way_players)\n",
    "    \n",
    "    # Merge batter stats\n",
    "    batter_stats = (batter_data[['IDfg', 'prediction_year', 'WAR', 'Position'] + \n",
    "                   [col for col in HITTER_COLUMNS if col not in ['Name', 'IDfg', 'WAR', 'Position']]]\\\n",
    "                   .rename(columns={\n",
    "                       'prediction_year': 'Year',\n",
    "                       'BB%': 'BB%_bat',\n",
    "                       'K%': 'K%_bat',\n",
    "                       'Age': 'Age_bat',\n",
    "                       'WAR': 'WAR_batter',\n",
    "                       'Position': 'Position_batter'\n",
    "                   }))\n",
    "    \n",
    "    # Merge pitcher stats\n",
    "    pitcher_stats = (pd.concat([\n",
    "        sp_data[['IDfg', 'prediction_year', 'WAR', 'Position'] + \n",
    "                [col for col in PITCHER_COLUMNS if col not in ['Name', 'IDfg', 'WAR', 'Position']]],\n",
    "        rp_data[['IDfg', 'prediction_year', 'WAR', 'Position'] + \n",
    "                [col for col in PITCHER_COLUMNS if col not in ['Name', 'IDfg', 'WAR', 'Position']]]\n",
    "    ])\\\n",
    "    .rename(columns={\n",
    "        'prediction_year': 'Year',\n",
    "        'BB%': 'BB%_pit',\n",
    "        'K%': 'K%_pit',\n",
    "        'Age': 'Age_pit',\n",
    "        'WAR': 'WAR_pitcher',\n",
    "        'Position': 'Position_pitcher'\n",
    "    })\\\n",
    "    .drop_duplicates(subset=['IDfg', 'Year']))\n",
    "    \n",
    "    # Merge stats\n",
    "    prediction_data = prediction_data.merge(batter_stats, on=['IDfg', 'Year'], how='left')\n",
    "    prediction_data = prediction_data.merge(pitcher_stats, on=['IDfg', 'Year'], how='left')\n",
    "    \n",
    "    # Handle positions and WAR for two-way players\n",
    "    mask = prediction_data['Two_Way']\n",
    "    \n",
    "    # Combine positions\n",
    "    prediction_data.loc[mask, 'Position'] = prediction_data.loc[mask].apply(\n",
    "        lambda x: f\"{x['Position_pitcher']}/{x['Position_batter']}\" if pd.notna(x['Position_pitcher']) else x['Position_batter'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Single position for non-two-way players\n",
    "    prediction_data.loc[~mask, 'Position'] = prediction_data.loc[~mask, 'Position_batter'].fillna(prediction_data.loc[~mask, 'Position_pitcher'])\n",
    "    \n",
    "    # Handle WAR\n",
    "    prediction_data.loc[mask, 'WAR'] = (\n",
    "        prediction_data.loc[mask, 'WAR_batter'].fillna(0) + \n",
    "        prediction_data.loc[mask, 'WAR_pitcher'].fillna(0)\n",
    "    )\n",
    "    prediction_data.loc[~mask, 'WAR'] = prediction_data.loc[~mask, 'WAR_batter'].fillna(prediction_data.loc[~mask, 'WAR_pitcher'])\n",
    "    \n",
    "    # Clean up columns\n",
    "    prediction_data = prediction_data.drop(['Position_batter', 'Position_pitcher'], axis=1)\n",
    "    prediction_data['Age'] = prediction_data['Age_bat'].fillna(prediction_data['Age_pit'])\n",
    "    prediction_data = prediction_data.drop(['Age_bat', 'Age_pit'], axis=1)\n",
    "    \n",
    "    # Combine and sort\n",
    "    result = pd.concat([historical_data, prediction_data])\n",
    "    return result.sort_values(['IDfg', 'Year'])\n",
    "\n",
    "# Execute\n",
    "try:\n",
    "    export_data = integrate_player_statistics(\n",
    "        timeline_with_history,\n",
    "        batter_data,\n",
    "        sp_data, \n",
    "        rp_data\n",
    "    )\n",
    "    print(f\"Records processed: {len(export_data)}\")\n",
    "    print(f\"Columns: {export_data.columns.tolist()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace status with normalized status\n",
    "export_data['Status']=export_data['Normalized_Status']\n",
    "export_data=export_data.drop('Normalized_Status',axis=1)\n",
    "export_data=export_data.drop('Contract_Value',axis=1)\n",
    "export_data=export_data.drop('Payroll',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example players with adjusted FA years:\n",
      "                 Name  Year Status  surplus_value  FA_Year  probable_fa_year\n",
      "86  Giancarlo Stanton  2010     NA            NaN   2029.0            2028.0\n",
      "87  Giancarlo Stanton  2011     NA            NaN   2029.0            2028.0\n",
      "88  Giancarlo Stanton  2012     NA            NaN   2029.0            2028.0\n",
      "89  Giancarlo Stanton  2013     NA            NaN   2029.0            2028.0\n",
      "90  Giancarlo Stanton  2014     NA            NaN   2029.0            2028.0\n"
     ]
    }
   ],
   "source": [
    "def analyze_contract_options(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add FA year and probable FA year analysis.\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Find base FA year\n",
    "    fa_years = (result[result['Status'] == 'Free Agent']\n",
    "                .groupby('IDfg')['Year']\n",
    "                .min()\n",
    "                .reset_index()\n",
    "                .rename(columns={'Year': 'FA_Year'}))\n",
    "    \n",
    "    result = result.merge(fa_years, on='IDfg', how='left')\n",
    "    result['probable_fa_year'] = result['FA_Year']\n",
    "    \n",
    "    # Find players with any type of option\n",
    "    option_types = ['Player Option', 'Team Option', 'Mutual Option', 'Vesting Option', 'Opt-Out']\n",
    "    \n",
    "    # Set earliest_fa_year to option year if exists, otherwise FA_Year\n",
    "    option_years = (result[result['Status'].isin(option_types)]\n",
    "                   .groupby('IDfg')['Year']\n",
    "                   .min()\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'Year': 'option_year'}))\n",
    "    \n",
    "    result['earliest_fa_year'] = result['FA_Year']\n",
    "    result = result.merge(option_years, on='IDfg', how='left')\n",
    "    result.loc[result['option_year'].notna(), 'earliest_fa_year'] = result.loc[result['option_year'].notna(), 'option_year']\n",
    "    \n",
    "    # Process each option type\n",
    "    for player_id in result[result['Status'].isin(option_types)]['IDfg'].unique():\n",
    "        player_data = result[result['IDfg'] == player_id].sort_values('Year')\n",
    "        option_status = player_data[player_data['Status'].isin(option_types)]['Status'].iloc[0]\n",
    "        option_year = player_data[player_data['Status'].isin(option_types)]['Year'].min()\n",
    "        fa_year = player_data['FA_Year'].iloc[0]\n",
    "        \n",
    "        # Calculate surplus sum from option year to FA year\n",
    "        surplus_sum = player_data[\n",
    "            (player_data['Year'] >= option_year) & \n",
    "            (player_data['Year'] < fa_year)\n",
    "        ]['surplus_value'].sum()\n",
    "        \n",
    "        # Apply option-specific logic\n",
    "        if option_status in ['Player Option', 'Opt-Out']:  # Treating Opt-Out like Player Option\n",
    "            if surplus_sum > 0:  # Player opts out if positive surplus\n",
    "                result.loc[result['IDfg'] == player_id, 'probable_fa_year'] = option_year\n",
    "        elif option_status == 'Team Option':\n",
    "            if surplus_sum < 0:  # Team declines if negative surplus\n",
    "                result.loc[result['IDfg'] == player_id, 'probable_fa_year'] = option_year\n",
    "        else:  # Other option types (Mutual, Vesting)\n",
    "            if surplus_sum < 0:  # Option declined if negative surplus\n",
    "                result.loc[result['IDfg'] == player_id, 'probable_fa_year'] = option_year\n",
    "    \n",
    "    # Clean up temporary column\n",
    "    result = result.drop('option_year', axis=1, errors='ignore')\n",
    "    \n",
    "    return result\n",
    "\n",
    "try:\n",
    "    export_data = analyze_contract_options(export_data)\n",
    "    \n",
    "    # Verify results\n",
    "    option_examples = export_data[\n",
    "        export_data['FA_Year'] != export_data['probable_fa_year']\n",
    "    ][['Name', 'Year', 'Status', 'surplus_value', 'FA_Year', 'probable_fa_year']].head()\n",
    "    \n",
    "    print(\"\\nExample players with adjusted FA years:\")\n",
    "    print(option_examples)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to analyze options: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round and handle negative values, preserving NaN\n",
    "columns_to_process = ['HR', '2B', '3B', 'RBI', 'R', 'SB', 'CS']\n",
    "\n",
    "for col in columns_to_process:\n",
    "    # Handle negative values first, preserve NaN\n",
    "    export_data[col] = export_data[col].apply(lambda x: max(x, 0) if pd.notna(x) else x)\n",
    "    # Round values, preserve NaN\n",
    "    export_data[col] = export_data[col].apply(lambda x: round(x) if pd.notna(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add ops, only for columns where obp and slg are not null\n",
    "export_data['OPS']=np.where(export_data['OBP'].notna() & export_data['SLG'].notna(),export_data['OBP']+export_data['SLG'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:32,010 - INFO - Starting value data export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:20:32,591 - INFO - Exported 14872 records to c:\\Users\\User\\Desktop\\LSTMLB\\data\\generated\\value_by_year\\player_values_complete.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status Distribution:\n",
      "Status  Arb-1  Arb-1 (Super 2)  Arb-2  Arb-3  Arb-4  Free Agent  \\\n",
      "Year                                                              \n",
      "2008        0                0      0      0      0           0   \n",
      "2009        0                0      0      0      0           0   \n",
      "2010        0                0      0      0      0           0   \n",
      "2011        0                0      0      0      0           0   \n",
      "2012        0                0      0      0      0           0   \n",
      "2013        0                0      0      0      0           0   \n",
      "2014        0                0      0      0      0           0   \n",
      "2015        0                0      0      0      0           0   \n",
      "2016        0                0      0      0      0           0   \n",
      "2017        0                0      0      0      0           0   \n",
      "2018        0                0      0      0      0           0   \n",
      "2019        0                0      0      0      0           0   \n",
      "2020        0                0      0      0      0           0   \n",
      "2021        0                0      0      0      0           0   \n",
      "2022        0                0      0      0      0           0   \n",
      "2023        0                0      0      0      0           0   \n",
      "2024        0                0      0      0      0           0   \n",
      "2025       95                0     65     55      2           1   \n",
      "2026       90               37     87     69     13          82   \n",
      "2027      115                1    124     87     13         197   \n",
      "2028      121                0    116    124     24         301   \n",
      "2029        0                0    121    116     37         440   \n",
      "2030        0                0      0    121      1         595   \n",
      "2031        0                0      0      0      0         729   \n",
      "2032        0                0      0      0      0         737   \n",
      "2033        0                0      0      0      0         744   \n",
      "2034        0                0      0      0      0         753   \n",
      "2035        0                0      0      0      0         755   \n",
      "2036        0                0      0      0      0         756   \n",
      "2037        0                0      0      0      0         756   \n",
      "2038        0                0      0      0      0         757   \n",
      "2039        0                0      0      0      0         757   \n",
      "\n",
      "Status  Mutual Option   NA  Opt-Out  Player Option  Pre-Arb  Signed  \\\n",
      "Year                                                                  \n",
      "2008                0    1        0              0        0       0   \n",
      "2009                0    1        0              0        0       0   \n",
      "2010                0    5        0              0        0       0   \n",
      "2011                0   10        0              0        0       0   \n",
      "2012                0   17        0              0        0       0   \n",
      "2013                0   38        0              0        0       0   \n",
      "2014                0   56        0              0        0       0   \n",
      "2015                0   73        0              0        0       0   \n",
      "2016                0  111        0              0        0       0   \n",
      "2017                0  146        0              0        0       0   \n",
      "2018                0  191        0              0        0       0   \n",
      "2019                0  255        0              0        0       0   \n",
      "2020                0  295        0              0        0       0   \n",
      "2021                0  400        0              0        0       0   \n",
      "2022                0  527        0              0        0       0   \n",
      "2023                0  646        0              0        0       0   \n",
      "2024                0  741        0              0        0       0   \n",
      "2025                0    0        3              9      366     149   \n",
      "2026                6    0        6              5      236      99   \n",
      "2027                3    0        2              3      121      71   \n",
      "2028                0    0        0              1        0      53   \n",
      "2029                1    0        0              0        0      38   \n",
      "2030                0    0        2              0        0      29   \n",
      "2031                0    0        1              0        0      21   \n",
      "2032                0    0        2              0        0      13   \n",
      "2033                0    0        1              0        0      11   \n",
      "2034                0    0        1              0        0       4   \n",
      "2035                0    0        0              0        0       2   \n",
      "2036                0    0        0              0        0       1   \n",
      "2037                0    0        0              0        0       1   \n",
      "2038                0    0        0              0        0       1   \n",
      "2039                0    0        0              0        0       1   \n",
      "\n",
      "Status  Team Option  Unknown  Vesting Option  \n",
      "Year                                          \n",
      "2008              0        0               0  \n",
      "2009              0        0               0  \n",
      "2010              0        0               0  \n",
      "2011              0        0               0  \n",
      "2012              0        0               0  \n",
      "2013              0        0               0  \n",
      "2014              0        0               0  \n",
      "2015              0        0               0  \n",
      "2016              0        0               0  \n",
      "2017              0        0               0  \n",
      "2018              0        0               0  \n",
      "2019              0        0               0  \n",
      "2020              0        0               0  \n",
      "2021              0        0               0  \n",
      "2022              0        0               0  \n",
      "2023              0        0               0  \n",
      "2024              0        0               0  \n",
      "2025             13        1               1  \n",
      "2026             21        0               2  \n",
      "2027             15        0               1  \n",
      "2028             12        0               3  \n",
      "2029              4        0               1  \n",
      "2030              9        0               1  \n",
      "2031              6        0               1  \n",
      "2032              5        0               1  \n",
      "2033              2        0               0  \n",
      "2034              0        0               0  \n",
      "2035              1        0               0  \n",
      "2036              1        0               0  \n",
      "2037              1        0               0  \n",
      "2038              0        0               0  \n",
      "2039              0        0               0  \n",
      "\n",
      "Status Distribution:\n",
      "Status  Arb-1  Arb-1 (Super 2)  Arb-2  Arb-3  Arb-4  Free Agent  \\\n",
      "Year                                                              \n",
      "2008        0                0      0      0      0           0   \n",
      "2009        0                0      0      0      0           0   \n",
      "2010        0                0      0      0      0           0   \n",
      "2011        0                0      0      0      0           0   \n",
      "2012        0                0      0      0      0           0   \n",
      "2013        0                0      0      0      0           0   \n",
      "2014        0                0      0      0      0           0   \n",
      "2015        0                0      0      0      0           0   \n",
      "2016        0                0      0      0      0           0   \n",
      "2017        0                0      0      0      0           0   \n",
      "2018        0                0      0      0      0           0   \n",
      "2019        0                0      0      0      0           0   \n",
      "2020        0                0      0      0      0           0   \n",
      "2021        0                0      0      0      0           0   \n",
      "2022        0                0      0      0      0           0   \n",
      "2023        0                0      0      0      0           0   \n",
      "2024        0                0      0      0      0           0   \n",
      "2025       95                0     65     55      2           1   \n",
      "2026       90               37     87     69     13          82   \n",
      "2027      115                1    124     87     13         197   \n",
      "2028      121                0    116    124     24         301   \n",
      "2029        0                0    121    116     37         440   \n",
      "2030        0                0      0    121      1         595   \n",
      "2031        0                0      0      0      0         729   \n",
      "2032        0                0      0      0      0         737   \n",
      "2033        0                0      0      0      0         744   \n",
      "2034        0                0      0      0      0         753   \n",
      "2035        0                0      0      0      0         755   \n",
      "2036        0                0      0      0      0         756   \n",
      "2037        0                0      0      0      0         756   \n",
      "2038        0                0      0      0      0         757   \n",
      "2039        0                0      0      0      0         757   \n",
      "\n",
      "Status  Mutual Option   NA  Opt-Out  Player Option  Pre-Arb  Signed  \\\n",
      "Year                                                                  \n",
      "2008                0    1        0              0        0       0   \n",
      "2009                0    1        0              0        0       0   \n",
      "2010                0    5        0              0        0       0   \n",
      "2011                0   10        0              0        0       0   \n",
      "2012                0   17        0              0        0       0   \n",
      "2013                0   38        0              0        0       0   \n",
      "2014                0   56        0              0        0       0   \n",
      "2015                0   73        0              0        0       0   \n",
      "2016                0  111        0              0        0       0   \n",
      "2017                0  146        0              0        0       0   \n",
      "2018                0  191        0              0        0       0   \n",
      "2019                0  255        0              0        0       0   \n",
      "2020                0  295        0              0        0       0   \n",
      "2021                0  400        0              0        0       0   \n",
      "2022                0  527        0              0        0       0   \n",
      "2023                0  646        0              0        0       0   \n",
      "2024                0  741        0              0        0       0   \n",
      "2025                0    0        3              9      366     149   \n",
      "2026                6    0        6              5      236      99   \n",
      "2027                3    0        2              3      121      71   \n",
      "2028                0    0        0              1        0      53   \n",
      "2029                1    0        0              0        0      38   \n",
      "2030                0    0        2              0        0      29   \n",
      "2031                0    0        1              0        0      21   \n",
      "2032                0    0        2              0        0      13   \n",
      "2033                0    0        1              0        0      11   \n",
      "2034                0    0        1              0        0       4   \n",
      "2035                0    0        0              0        0       2   \n",
      "2036                0    0        0              0        0       1   \n",
      "2037                0    0        0              0        0       1   \n",
      "2038                0    0        0              0        0       1   \n",
      "2039                0    0        0              0        0       1   \n",
      "\n",
      "Status  Team Option  Unknown  Vesting Option  \n",
      "Year                                          \n",
      "2008              0        0               0  \n",
      "2009              0        0               0  \n",
      "2010              0        0               0  \n",
      "2011              0        0               0  \n",
      "2012              0        0               0  \n",
      "2013              0        0               0  \n",
      "2014              0        0               0  \n",
      "2015              0        0               0  \n",
      "2016              0        0               0  \n",
      "2017              0        0               0  \n",
      "2018              0        0               0  \n",
      "2019              0        0               0  \n",
      "2020              0        0               0  \n",
      "2021              0        0               0  \n",
      "2022              0        0               0  \n",
      "2023              0        0               0  \n",
      "2024              0        0               0  \n",
      "2025             13        1               1  \n",
      "2026             21        0               2  \n",
      "2027             15        0               1  \n",
      "2028             12        0               3  \n",
      "2029              4        0               1  \n",
      "2030              9        0               1  \n",
      "2031              6        0               1  \n",
      "2032              5        0               1  \n",
      "2033              2        0               0  \n",
      "2034              0        0               0  \n",
      "2035              1        0               0  \n",
      "2036              1        0               0  \n",
      "2037              1        0               0  \n",
      "2038              0        0               0  \n",
      "2039              0        0               0  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Value Export Module\n",
    "Exports yearly player valuations sorted by team and WAR\n",
    "\"\"\"\n",
    "\n",
    "def export_value_data(df: pd.DataFrame, output_dir: Path) -> None:\n",
    "    \"\"\"Export sorted value data by year.\"\"\"\n",
    "    logger.info(\"Starting value data export\")\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define column groups\n",
    "    base_cols = [\n",
    "        'Player Name', 'Team', 'Status', 'Position', 'Age', 'WAR',\n",
    "        'Base_Value', 'Contract_Value', 'Surplus_Value', 'IDfg', 'Year', 'FA_Year', 'Probable_FA_Year', 'Earliest_FA_Year',\n",
    "    ]\n",
    "    \n",
    "    hitting_cols = [\n",
    "        'BB%_bat', 'K%_bat', 'AVG', 'OBP', 'SLG', 'OPS',\n",
    "        'wOBA', 'wRC+', 'Off', 'BsR', 'Def', 'WAR_batter', 'HR', '2B', '3B', 'SB', 'CS', 'R', 'RBI'\n",
    "    ]\n",
    "    \n",
    "    pitching_cols = [\n",
    "        'ERA', 'FIP', 'SIERA', 'K%_pit', 'BB%_pit', 'WAR_pitcher'\n",
    "    ]\n",
    "    \n",
    "    export_cols = base_cols + hitting_cols + pitching_cols\n",
    "    \n",
    "    try:\n",
    "        # Create copy for export\n",
    "        export_df = df.copy()\n",
    "        \n",
    "        # Rename Name column\n",
    "        export_df = export_df.rename(columns={'Name': 'Player_Name'})\n",
    "        \n",
    "        # Sort data\n",
    "        export_df = export_df.sort_values(['Year', 'Team', 'WAR'], \n",
    "                                        ascending=[True, True, False])\n",
    "        \n",
    "        # Round numeric columns\n",
    "        numeric_cols = ['Base_Value', 'Contract_Value', 'surplus_value', 'WAR']\n",
    "        for col in numeric_cols:\n",
    "            if col in export_df.columns:\n",
    "                export_df[col] = export_df[col].round(2)\n",
    "        \n",
    "        # Export to single file\n",
    "        output_file = output_dir / 'player_values_complete.csv'\n",
    "        export_df.to_csv(output_file, index=False, na_rep='')\n",
    "        \n",
    "        logger.info(f\"Exported {len(export_df)} records to {output_file}\")\n",
    "        \n",
    "        # Print status distribution\n",
    "        print(\"\\nStatus Distribution:\")\n",
    "        print(export_df.groupby(['Year', 'Status']).size().unstack(fill_value=0))\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Export process failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "   \n",
    "    # Execute export\n",
    "    export_value_data(export_data, OUTPUT_DIR)\n",
    "    \n",
    "    # Print status distribution\n",
    "    print(\"\\nStatus Distribution:\")\n",
    "    print(export_data.groupby(['Year', 'Status']).size().unstack(fill_value=0))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Export process failed: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:58,307 - INFO - Initialized MLB Trade Simulator value determination module\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MLB Trade Simulator - Value Determination Module\n",
    "Author: Niels Christoffersen\n",
    "Version: 1.0\n",
    "Last Updated: 12/23/2024\n",
    "\n",
    "This module calculates player values based on WAR projections and contract status.\n",
    "It handles data loading, cleaning, and value calculations for MLB players.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Type aliases\n",
    "PathLike = str | Path\n",
    "\n",
    "# Global constants\n",
    "ROOT_DIR = Path(os.getcwd()).parent  # Changed from Path(__file__).parent.parent\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "GENERATED_DIR = DATA_DIR / 'generated'\n",
    "OUTPUT_DIR = GENERATED_DIR / 'value_by_year'\n",
    "HITTER_COLUMNS = [\n",
    "    'Name', 'Age', 'IDfg', 'BB%', 'K%', 'AVG', 'OBP', 'SLG', 'wOBA', \n",
    "    'wRC+', 'EV', 'Off', 'BsR', 'Def', 'WAR'\n",
    "]\n",
    "\n",
    "PITCHER_COLUMNS = [\n",
    "    'Name', 'Age', 'IDfg', 'ERA','FIP', 'SIERA', 'K%', 'BB%', 'WAR'\n",
    "]\n",
    "# Ensure required directories exist\n",
    "for directory in [DATA_DIR, GENERATED_DIR, OUTPUT_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    logger.debug(f\"Verified directory exists: {directory}\")\n",
    "\n",
    "logger.info(\"Initialized MLB Trade Simulator value determination module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:58,335 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2025.csv\n",
      "2025-01-11 20:06:58,344 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2026.csv\n",
      "2025-01-11 20:06:58,351 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2027.csv\n",
      "2025-01-11 20:06:58,359 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2028.csv\n",
      "2025-01-11 20:06:58,365 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2029.csv\n",
      "2025-01-11 20:06:58,373 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2030.csv\n",
      "2025-01-11 20:06:58,379 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2031.csv\n",
      "2025-01-11 20:06:58,384 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2032.csv\n",
      "2025-01-11 20:06:58,390 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2033.csv\n",
      "2025-01-11 20:06:58,394 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2034.csv\n",
      "2025-01-11 20:06:58,399 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2035.csv\n",
      "2025-01-11 20:06:58,403 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2036.csv\n",
      "2025-01-11 20:06:58,408 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2037.csv\n",
      "2025-01-11 20:06:58,412 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2038.csv\n",
      "2025-01-11 20:06:58,416 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\SP_Predictions_2039.csv\n",
      "2025-01-11 20:06:58,424 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2025.csv\n",
      "2025-01-11 20:06:58,430 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2026.csv\n",
      "2025-01-11 20:06:58,435 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2027.csv\n",
      "2025-01-11 20:06:58,442 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2028.csv\n",
      "2025-01-11 20:06:58,447 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2029.csv\n",
      "2025-01-11 20:06:58,453 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2030.csv\n",
      "2025-01-11 20:06:58,459 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2031.csv\n",
      "2025-01-11 20:06:58,464 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2032.csv\n",
      "2025-01-11 20:06:58,471 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2033.csv\n",
      "2025-01-11 20:06:58,477 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2034.csv\n",
      "2025-01-11 20:06:58,482 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2035.csv\n",
      "2025-01-11 20:06:58,488 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2036.csv\n",
      "2025-01-11 20:06:58,494 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2037.csv\n",
      "2025-01-11 20:06:58,500 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2038.csv\n",
      "2025-01-11 20:06:58,508 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\RP_Predictions_2039.csv\n",
      "2025-01-11 20:06:58,518 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2025.csv\n",
      "2025-01-11 20:06:58,543 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2026.csv\n",
      "2025-01-11 20:06:58,554 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2027.csv\n",
      "2025-01-11 20:06:58,563 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2028.csv\n",
      "2025-01-11 20:06:58,573 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2029.csv\n",
      "2025-01-11 20:06:58,581 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2030.csv\n",
      "2025-01-11 20:06:58,589 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2031.csv\n",
      "2025-01-11 20:06:58,595 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2032.csv\n",
      "2025-01-11 20:06:58,601 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2033.csv\n",
      "2025-01-11 20:06:58,608 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2034.csv\n",
      "2025-01-11 20:06:58,614 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2035.csv\n",
      "2025-01-11 20:06:58,621 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2036.csv\n",
      "2025-01-11 20:06:58,628 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2037.csv\n",
      "2025-01-11 20:06:58,634 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2038.csv\n",
      "2025-01-11 20:06:58,652 - INFO - Loading c:\\Users\\User\\Desktop\\MLBTradeSim\\data\\generated\\Batter_Predictions_2039.csv\n",
      "2025-01-11 20:06:58,671 - INFO - Loaded 3400 SP, 6884 RP, 6090 batter, and 3821 salary records\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "PREDICTION_YEARS = range(2025, 2040)\n",
    "REQUIRED_COLUMNS = {\n",
    "    'predictions': ['Name', 'IDfg', 'Age', 'WAR'],\n",
    "    'salary': ['Name', 'IDfg', 'Salary', 'Contract_Status']\n",
    "}\n",
    "\n",
    "def validate_files_exist(pattern: str, years: range) -> None:\n",
    "    \"\"\"Validate prediction files exist for given years.\"\"\"\n",
    "    missing_files = [\n",
    "        f\"{pattern}_{year}.csv\" \n",
    "        for year in years \n",
    "        if not (GENERATED_DIR / f\"{pattern}_{year}.csv\").exists()\n",
    "    ]\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Missing files: {', '.join(missing_files)}\")\n",
    "\n",
    "def load_prediction_files(pattern: str, years: range = PREDICTION_YEARS) -> DataFrame:\n",
    "    \"\"\"Load and combine prediction CSVs with validation.\"\"\"\n",
    "    validate_files_exist(pattern, years)\n",
    "    dfs = []\n",
    "    \n",
    "    for year in years:\n",
    "        file_path = GENERATED_DIR / f\"{pattern}_{year}.csv\"\n",
    "        logger.info(f\"Loading {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            missing_cols = set(REQUIRED_COLUMNS['predictions']) - set(df.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns in {file_path}: {missing_cols}\")\n",
    "                \n",
    "            df['prediction_year'] = year\n",
    "            dfs.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {file_path}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Main data loading\n",
    "try:\n",
    "    sp_data = load_prediction_files('SP_Predictions')\n",
    "    rp_data = load_prediction_files('RP_Predictions')\n",
    "    batter_data = load_prediction_files('Batter_Predictions')\n",
    "    salary_data = pd.read_csv(DATA_DIR / 'SPORTRAC_MLB_SALARY_DATA.csv')\n",
    "    \n",
    "    logger.info(f\"Loaded {len(sp_data)} SP, {len(rp_data)} RP, \"\n",
    "                f\"{len(batter_data)} batter, and {len(salary_data)} salary records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Critical error during data loading: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Positions, and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:58,704 - INFO - SP columns: ['Name', 'Season', 'Age', 'IDfg', 'ERA', 'FIP', 'SIERA', 'K%', 'BB%', 'HR/9', 'SwStr%', 'Contact%', 'O-Swing%', 'Z-Contact%', 'F-Strike%', 'Zone%', 'CSW%', 'CStr%', 'IP', 'G', 'GS', 'WAR', 'prediction_year', 'position_group', 'Position']\n",
      "2025-01-11 20:06:58,705 - INFO - RP columns: ['Name', 'Season', 'Age', 'IDfg', 'ERA', 'FIP', 'SIERA', 'K%', 'BB%', 'HR/9', 'SwStr%', 'Contact%', 'O-Swing%', 'Z-Contact%', 'F-Strike%', 'Zone%', 'CSW%', 'CStr%', 'IP', 'G', 'GS', 'WAR', 'prediction_year', 'position_group', 'Position']\n",
      "2025-01-11 20:06:58,706 - INFO - Batter columns: ['Name', 'Age', 'Year', 'IDfg', 'BB%', 'K%', 'BABIP', 'AVG', 'OBP', 'SLG', 'wOBA', 'wRC+', 'Barrel%', 'HardHit%', 'EV', 'wSB_rate', 'UBR_rate', 'wGDP_rate', 'Def_rate', 'def_value', 'Position', 'Off', 'BsR', 'Def', 'WAR', 'prediction_year', 'position_group']\n",
      "2025-01-11 20:06:58,781 - INFO - \n",
      "Prediction Data Summary:\n",
      "2025-01-11 20:06:58,812 - WARNING - \n",
      "Missing values found:\n",
      "WAR    15\n",
      "dtype: int64\n",
      "2025-01-11 20:06:58,814 - INFO - Successfully merged 16374 player predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                count   mean    std     min    max\n",
      "position_group prediction_year                                    \n",
      "POS            2025               405  1.004  2.077  -5.880  6.812\n",
      "               2026               405  0.594  2.303  -6.666  7.165\n",
      "               2027               405  0.161  2.466  -7.832  7.427\n",
      "               2028               405 -0.261  2.646  -8.622  7.477\n",
      "               2029               405 -0.707  2.821  -9.129  7.505\n",
      "               2030               405 -1.179  2.973  -9.506  7.613\n",
      "               2031               405 -1.656  3.087  -9.752  7.642\n",
      "               2032               405 -2.140  3.144  -9.845  7.588\n",
      "               2033               405 -2.616  3.128  -9.762  7.461\n",
      "               2034               405 -3.075  3.037 -10.051  7.175\n",
      "               2035               405 -3.491  2.886 -10.357  6.736\n",
      "               2036               405 -3.852  2.707 -10.408  6.059\n",
      "               2037               405 -4.142  2.518 -10.274  4.954\n",
      "               2038               405 -4.348  2.348 -10.367  3.489\n",
      "               2039               405 -4.460  2.214 -10.421  2.398\n",
      "RP             2025               462  0.811  0.312   0.400  2.200\n",
      "               2026               462  0.723  0.259   0.300  2.400\n",
      "               2027               462  0.667  0.215   0.300  2.200\n",
      "               2028               462  0.597  0.174   0.300  2.100\n",
      "               2029               462  0.545  0.146   0.300  1.800\n",
      "               2030               462  0.509  0.131   0.300  1.600\n",
      "               2031               462  0.474  0.114   0.300  1.200\n",
      "               2032               462  0.445  0.100   0.300  0.900\n",
      "               2033               462  0.424  0.091   0.300  0.700\n",
      "               2034               462  0.406  0.080   0.300  0.700\n",
      "               2035               462  0.388  0.074   0.300  0.700\n",
      "               2036               462  0.373  0.067   0.300  0.700\n",
      "               2037               462  0.363  0.061   0.300  0.600\n",
      "               2038               462  0.357  0.056   0.300  0.600\n",
      "               2039               416  0.355  0.054   0.300  0.600\n",
      "SP             2025               227  2.446  1.324  -0.000  6.100\n",
      "               2026               227  2.386  1.455  -0.300  6.600\n",
      "               2027               227  2.307  1.579  -0.600  6.600\n",
      "               2028               227  2.111  1.660  -0.600  6.500\n",
      "               2029               227  1.940  1.734  -0.600  6.500\n",
      "               2030               227  1.747  1.759  -0.400  6.400\n",
      "               2031               227  1.544  1.755  -0.400  6.400\n",
      "               2032               227  1.344  1.717  -0.500  6.300\n",
      "               2033               227  1.142  1.644  -0.500  6.200\n",
      "               2034               227  0.953  1.541  -0.400  6.200\n",
      "               2035               227  0.772  1.422  -0.400  6.000\n",
      "               2036               227  0.607  1.288  -0.300  5.900\n",
      "               2037               227  0.463  1.136  -0.300  5.600\n",
      "               2038               227  0.348  0.985  -0.300  5.300\n",
      "               2039               222  0.265  0.843  -0.300  5.000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Position Grouping and Data Merging\n",
    "- Groups player positions into SP/RP/POS categories\n",
    "- Merges prediction datasets\n",
    "- Validates data quality\n",
    "- Provides summary statistics\n",
    "\"\"\"\n",
    "\n",
    "# Add position grouping\n",
    "sp_data['position_group'] = 'SP'\n",
    "rp_data['position_group'] = 'RP'\n",
    "batter_data['position_group'] = 'POS'\n",
    "\n",
    "sp_data['Position'] = sp_data['Role']\n",
    "rp_data['Position'] = rp_data['Role']\n",
    "sp_data = sp_data.drop('Role', axis=1)\n",
    "rp_data = rp_data.drop('Role', axis=1)\n",
    "def merge_prediction_data(sp_df, rp_df, batter_df):\n",
    "    \"\"\"Merge prediction datasets with validation.\"\"\"\n",
    "    required_cols = [\n",
    "        'Name', 'IDfg', 'position_group', 'Age', \n",
    "        'prediction_year', 'WAR', 'Position'\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"SP columns: {sp_df.columns.tolist()}\")\n",
    "    logger.info(f\"RP columns: {rp_df.columns.tolist()}\")\n",
    "    logger.info(f\"Batter columns: {batter_df.columns.tolist()}\")\n",
    "    \n",
    "    # Combine datasets\n",
    "    player_predictions = pd.concat([\n",
    "        sp_df[sp_df.columns.intersection(required_cols + ['Position'])],\n",
    "        rp_df[rp_df.columns.intersection(required_cols + ['Position'])],\n",
    "        batter_df[batter_df.columns.intersection(required_cols + ['Position'])]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Verify Position exists\n",
    "    if 'Position' not in player_predictions.columns:\n",
    "        raise ValueError(\"Position column lost during merge\")\n",
    "        \n",
    "    return player_predictions\n",
    "\n",
    "# Merge data and generate summary\n",
    "try:\n",
    "    player_predictions = merge_prediction_data(sp_data, rp_data, batter_data)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    summary = player_predictions.groupby(['position_group', 'prediction_year'])['WAR'].agg([\n",
    "        'count',\n",
    "        'mean',\n",
    "        'std',\n",
    "        'min',\n",
    "        'max'\n",
    "    ]).round(3)\n",
    "    \n",
    "    logger.info(\"\\nPrediction Data Summary:\")\n",
    "    print(summary)\n",
    "    \n",
    "    # Validate no missing values\n",
    "    missing_values = player_predictions.isnull().sum()\n",
    "    if missing_values.any():\n",
    "        logger.warning(f\"\\nMissing values found:\\n{missing_values[missing_values > 0]}\")\n",
    "        \n",
    "    logger.info(f\"Successfully merged {len(player_predictions)} player predictions\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error merging prediction data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:58,843 - INFO - Starting salary data cleaning process\n",
      "2025-01-11 20:06:58,891 - INFO - \n",
      "Status distribution:\n",
      "2025-01-11 20:06:58,892 - INFO - Status\n",
      "Estimate       871\n",
      "PRE-ARB        740\n",
      "UFA            423\n",
      "ARB 1          278\n",
      "ARB 3          213\n",
      "              ... \n",
      "$2,370,968       1\n",
      "$36,571,428      1\n",
      "$28,071,428      1\n",
      "$10,015,872      1\n",
      "$2,962,963       1\n",
      "Name: count, Length: 134, dtype: int64\n",
      "2025-01-11 20:06:58,896 - INFO - \n",
      "Salary cleaning summary:\n",
      "2025-01-11 20:06:58,897 - INFO - original_rows: 3821\n",
      "2025-01-11 20:06:58,897 - INFO - cleaned_rows: 3806\n",
      "2025-01-11 20:06:58,899 - INFO - valid_salary_rows: 2043\n",
      "2025-01-11 20:06:58,902 - INFO - min_salary: 250,000.00\n",
      "2025-01-11 20:06:58,903 - INFO - max_salary: 51,875,000.00\n",
      "2025-01-11 20:06:58,905 - INFO - mean_salary: 10,248,524.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of cleaned salary data:\n",
      "      Player Name    Year Team     Payroll   Status\n",
      "0  Corbin Carroll  2023.0  ari   1625000.0      NaN\n",
      "1  Corbin Carroll  2024.0  ari   3625000.0  Pre-Arb\n",
      "2  Corbin Carroll  2025.0  ari   5625000.0  Pre-Arb\n",
      "3  Corbin Carroll  2026.0  ari  10625000.0    ARB 1\n",
      "4  Corbin Carroll  2027.0  ari  12625000.0    ARB 2\n",
      "\n",
      "Data validation:\n",
      "Null values:\n",
      "Player Name       0\n",
      "Year              0\n",
      "Team              0\n",
      "Payroll        1763\n",
      "Status          407\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Salary Data Processing Module\n",
    "- Cleans and standardizes salary data\n",
    "- Preserves contract status information\n",
    "- Handles missing and invalid values\n",
    "- Validates data quality\n",
    "\"\"\"\n",
    "\n",
    "def clean_salary_data(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Clean and standardize salary data from Sportrac.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Raw salary data with Payroll and Status columns\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Cleaned salary data with standardized values\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting salary data cleaning process\")\n",
    "    \n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    try:\n",
    "        # Remove non-player rows (options, buyouts, etc)\n",
    "        cleaned_df = cleaned_df[~cleaned_df['Player Name'].str.contains(\n",
    "            'OPT-OUT|UFA|PLAYER OPT|CLUB OPT', \n",
    "            na=False, \n",
    "            case=False\n",
    "        )]\n",
    "        \n",
    "        # Clean Year column\n",
    "        cleaned_df['Year'] = pd.to_numeric(cleaned_df['Year'], errors='coerce')\n",
    "        cleaned_df = cleaned_df.dropna(subset=['Year'])\n",
    "        \n",
    "        # Clean Payroll column - two-step process\n",
    "        payroll = (cleaned_df['Payroll']\n",
    "                  .astype(str)\n",
    "                  .str.replace('$', '', regex=False)\n",
    "                  .str.replace(',', '', regex=False)\n",
    "                  .str.replace('-', '', regex=False))\n",
    "        \n",
    "        cleaned_df['Payroll'] = pd.to_numeric(payroll, errors='coerce')\n",
    "        \n",
    "        # Status validation and cleaning\n",
    "        if 'Status' not in cleaned_df.columns:\n",
    "            logger.warning(\"Status column missing from input data\")\n",
    "        else:\n",
    "            status_counts = cleaned_df['Status'].value_counts()\n",
    "            logger.info(\"\\nStatus distribution:\")\n",
    "            logger.info(status_counts)\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        stats = {\n",
    "            'original_rows': len(df),\n",
    "            'cleaned_rows': len(cleaned_df),\n",
    "            'valid_salary_rows': cleaned_df['Payroll'].notna().sum(),\n",
    "            'min_salary': cleaned_df['Payroll'].min(),\n",
    "            'max_salary': cleaned_df['Payroll'].max(),\n",
    "            'mean_salary': cleaned_df['Payroll'].mean()\n",
    "        }\n",
    "        \n",
    "        logger.info(\"\\nSalary cleaning summary:\")\n",
    "        for key, value in stats.items():\n",
    "            logger.info(f\"{key}: {value:,.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "            \n",
    "        return cleaned_df[['Player Name', 'Year', 'Team', 'Payroll', 'Status']].copy()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning salary data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Execute cleaning\n",
    "try:\n",
    "    salary_data_clean = clean_salary_data(salary_data)\n",
    "    \n",
    "    print(\"\\nSample of cleaned salary data:\")\n",
    "    print(salary_data_clean.head())\n",
    "    \n",
    "    print(\"\\nData validation:\")\n",
    "    print(f\"Null values:\\n{salary_data_clean.isnull().sum()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process salary data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:59,649 - INFO - \n",
      "Merge Results:\n",
      "2025-01-11 20:06:59,649 - INFO - Total players: 1137\n",
      "2025-01-11 20:06:59,650 - INFO - Matched: 708\n",
      "2025-01-11 20:06:59,651 - INFO - Unmatched: 429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample unmatched players:\n",
      "['Tim Tawa' 'Jordan Lawlar' 'Joe Elbis' 'Cristian Mena' 'Jorge Barrosa'\n",
      " 'Yilber Diaz' 'Adrian Del Castillo' 'Blake Walston' 'Slade Cecconi'\n",
      " 'Blaze Alexander']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Player Reference and ID Integration with Enhanced Name Matching\n",
    "Handles UTF-8 encoding and accent normalization\n",
    "\"\"\"\n",
    "\n",
    "import unidecode\n",
    "from thefuzz import fuzz\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    \"\"\"Normalize player names by removing accents and standardizing format.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    return unidecode.unidecode(str(name)).upper().strip()\n",
    "\n",
    "def create_player_reference(sp_df: pd.DataFrame, \n",
    "                          rp_df: pd.DataFrame, \n",
    "                          batter_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create unified player reference with normalized names.\"\"\"\n",
    "    player_ref = pd.concat([\n",
    "        sp_df[['Name', 'IDfg', 'position_group']],\n",
    "        rp_df[['Name', 'IDfg', 'position_group']],\n",
    "        batter_df[['Name', 'IDfg', 'position_group']]\n",
    "    ]).drop_duplicates()\n",
    "    \n",
    "    player_ref['Name_Normalized'] = player_ref['Name'].apply(normalize_name)\n",
    "    return player_ref\n",
    "\n",
    "def merge_salary_with_ids(salary_df: pd.DataFrame, \n",
    "                         player_ref: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge salary data with player reference using normalized names.\"\"\"\n",
    "    # Normalize salary data names\n",
    "    salary_df['Name_Normalized'] = salary_df['Player Name'].apply(normalize_name)\n",
    "    \n",
    "    # Perform merge\n",
    "    merged_df = salary_df.merge(\n",
    "        player_ref[['Name_Normalized', 'IDfg']],\n",
    "        on='Name_Normalized',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Log matching statistics\n",
    "    total = len(salary_df['Player Name'].unique())\n",
    "    matched = len(merged_df[merged_df['IDfg'].notna()]['Player Name'].unique())\n",
    "    \n",
    "    logger.info(f\"\\nMerge Results:\")\n",
    "    logger.info(f\"Total players: {total}\")\n",
    "    logger.info(f\"Matched: {matched}\")\n",
    "    logger.info(f\"Unmatched: {total - matched}\")\n",
    "    \n",
    "    return merged_df.drop('Name_Normalized', axis=1)\n",
    "\n",
    "try:\n",
    "    player_ref = create_player_reference(sp_data, rp_data, batter_data)\n",
    "    salary_data_with_id = merge_salary_with_ids(salary_data_clean, player_ref)\n",
    "    \n",
    "    # Display unmatched players\n",
    "    unmatched = salary_data_with_id[salary_data_with_id['IDfg'].isna()]\n",
    "    if not unmatched.empty:\n",
    "        print(\"\\nSample unmatched players:\")\n",
    "        print(unmatched['Player Name'].unique()[:10])\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in ID integration: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:59,695 - INFO - Processing contract statuses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contract Processing Summary:\n",
      "Total players: 712\n",
      "Players with FA years: 708\n",
      "\n",
      "FA Years by Status:\n",
      "                      count     mean\n",
      "Status                              \n",
      "$1,250,000                1  2027.00\n",
      "$1,750,000                1  2026.00\n",
      "$1,800,000                1  2026.00\n",
      "$1,950,000                0      NaN\n",
      "$10,000,000               5  2026.80\n",
      "...                     ...      ...\n",
      "Pre-Arb                  33  2030.30\n",
      "RFA / QO                  0      NaN\n",
      "UFA                     391  2027.96\n",
      "Vesting                  10  2029.80\n",
      "arbitration-bypassed      2  2028.50\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Contract Status Processing Module\n",
    "- Determines Free Agency years for all players\n",
    "- Handles arbitration progression\n",
    "- Processes contract options and UFA designations\n",
    "- Validates contract timelines\n",
    "\"\"\"\n",
    "\n",
    "def determine_fa_year(status: str, current_year: int) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Calculate Free Agency year based on current status.\n",
    "    \n",
    "    Args:\n",
    "        status: Player's current contract status\n",
    "        current_year: Current season year\n",
    "        \n",
    "    Returns:\n",
    "        Optional[int]: Year player reaches free agency\n",
    "    \"\"\"\n",
    "    if not status or pd.isna(status):\n",
    "        return None\n",
    "        \n",
    "    status = str(status).upper().strip()\n",
    "    \n",
    "    # Direct FA indicators\n",
    "    if any(x in status for x in ['UFA', 'OPT-OUT', 'PLAYER']):\n",
    "        return current_year\n",
    "    \n",
    "    # Service time progression\n",
    "    status_to_years = {\n",
    "        'ESTIMATE': 6,\n",
    "        'PRE-ARB': 4,\n",
    "        'ARB1': 3,\n",
    "        'ARB 1': 3,\n",
    "        'ARB2': 2,\n",
    "        'ARB 2': 2,\n",
    "        'ARB3': 1,\n",
    "        'ARB 3': 1,\n",
    "        'ARB4': 1,\n",
    "        'ARB 4': 1\n",
    "    }\n",
    "    \n",
    "    for key, years in status_to_years.items():\n",
    "        if key in status:\n",
    "            return current_year + years\n",
    "            \n",
    "    return None\n",
    "\n",
    "\"\"\"\n",
    "Contract Status Processing with IDfg\n",
    "Determines FA years based on latest available status\n",
    "\"\"\"\n",
    "\n",
    "def process_contract_statuses(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process latest contract status for each player.\"\"\"\n",
    "    logger.info(\"Processing contract statuses\")\n",
    "    \n",
    "    # Get latest year for each player\n",
    "    latest_status = (df[df['IDfg'].notna()]\n",
    "                    .sort_values('Year', ascending=True)\n",
    "                    .groupby('IDfg')\n",
    "                    .last()\n",
    "                    .reset_index())\n",
    "    \n",
    "    # Calculate FA years\n",
    "    fa_years = {}\n",
    "    for _, player in latest_status.iterrows():\n",
    "        status = str(player.get('Status', '')).upper().strip()\n",
    "        current_year = int(player['Year'])\n",
    "        \n",
    "        # Direct FA indicators\n",
    "        if any(x in status for x in ['UFA', 'OPT-OUT', 'PLAYER']):\n",
    "            fa_years[player['IDfg']] = current_year\n",
    "        # Next year FA\n",
    "        elif any(x in status for x in ['CLUB', 'VESTING', 'ARB3', 'ARB 3', 'ARB4', 'ARB 4']):\n",
    "            fa_years[player['IDfg']] = current_year + 1\n",
    "        # Service time progression\n",
    "        elif any(x in status for x in ['ARB2', 'ARB 2']):\n",
    "            fa_years[player['IDfg']] = current_year + 2\n",
    "        elif any(x in status for x in ['ARB1', 'ARB 1']):\n",
    "            fa_years[player['IDfg']] = current_year + 3\n",
    "        elif 'PRE' in status and 'ARB' in status:\n",
    "            fa_years[player['IDfg']] = current_year + 4\n",
    "        elif status == 'ESTIMATE':\n",
    "            fa_years[player['IDfg']] = current_year + 6\n",
    "    \n",
    "    # Map FA years back to original data\n",
    "    df['FA_Year'] = df['IDfg'].map(fa_years)\n",
    "    \n",
    "    return df\n",
    "\n",
    "try:\n",
    "    contract_data = process_contract_statuses(salary_data_with_id)\n",
    "    \n",
    "    # Output validation summary\n",
    "    print(\"\\nContract Processing Summary:\")\n",
    "    print(f\"Total players: {len(contract_data['IDfg'].unique())}\")\n",
    "    print(f\"Players with FA years: {len(contract_data[contract_data['FA_Year'].notna()]['IDfg'].unique())}\")\n",
    "    print(\"\\nFA Years by Status:\")\n",
    "    print(contract_data.groupby('Status')['FA_Year'].agg(['count', 'mean']).round(2))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process contract statuses: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:06:59,798 - INFO - Generating contract timeline\n",
      "2025-01-11 20:07:00,255 - INFO - \n",
      "Status Distribution by Year:\n",
      "2025-01-11 20:07:00,277 - INFO - Status  $1,250,000  $1,750,000  $1,800,000  $10,000,000  $10,750,000  \\\n",
      "Year                                                                   \n",
      "2025.0           1           1           1            1            1   \n",
      "2026.0           0           0           0            0            0   \n",
      "2027.0           0           0           0            0            0   \n",
      "2028.0           0           0           0            0            0   \n",
      "2029.0           0           0           0            1            0   \n",
      "2030.0           0           0           0            0            0   \n",
      "2031.0           0           0           0            0            0   \n",
      "2032.0           0           0           0            0            0   \n",
      "2033.0           0           0           0            0            0   \n",
      "2034.0           0           0           0            0            0   \n",
      "2035.0           0           0           0            0            0   \n",
      "2036.0           0           0           0            0            0   \n",
      "2037.0           0           0           0            0            0   \n",
      "2038.0           0           0           0            0            0   \n",
      "2039.0           0           0           0            0            0   \n",
      "\n",
      "Status  $12,000,000  $12,500,000  $13,000,000  $13,142,857  $14,500,000  ...  \\\n",
      "Year                                                                     ...   \n",
      "2025.0            1            0            2            1            1  ...   \n",
      "2026.0            0            0            0            1            1  ...   \n",
      "2027.0            0            0            0            0            0  ...   \n",
      "2028.0            0            1            0            0            0  ...   \n",
      "2029.0            0            0            0            0            0  ...   \n",
      "2030.0            0            0            0            0            0  ...   \n",
      "2031.0            0            0            0            0            0  ...   \n",
      "2032.0            0            0            0            0            0  ...   \n",
      "2033.0            0            0            0            0            0  ...   \n",
      "2034.0            0            0            0            0            0  ...   \n",
      "2035.0            0            0            0            0            0  ...   \n",
      "2036.0            0            0            0            0            0  ...   \n",
      "2037.0            0            0            0            0            0  ...   \n",
      "2038.0            0            0            0            0            0  ...   \n",
      "2039.0            0            0            0            0            0  ...   \n",
      "\n",
      "Status    FA  Mutual  Opt-Out  PRE-ARB  Player  Pre-ARB  Pre-Arb  UFA  \\\n",
      "Year                                                                    \n",
      "2025.0     0       0        3        0       9        0        3    0   \n",
      "2026.0     0       5        5      198       5        3        0   82   \n",
      "2027.0   251       3        2      114       3        3        0  109   \n",
      "2028.0   650       0        0        0       1        0        0  102   \n",
      "2029.0  1361       1        0        0       0        0        0   53   \n",
      "2030.0  1941       0        2        0       0        0        0    6   \n",
      "2031.0  2335       0        1        0       0        0        0   12   \n",
      "2032.0  2438       0        2        0       0        0        0    8   \n",
      "2033.0  2521       0        1        0       0        0        0    5   \n",
      "2034.0  2576       0        1        0       0        0        0    9   \n",
      "2035.0  2680       0        0        0       0        0        0    2   \n",
      "2036.0  2708       0        0        0       0        0        0    1   \n",
      "2037.0  2721       0        0        0       0        0        0    0   \n",
      "2038.0  2721       0        0        0       0        0        0    1   \n",
      "2039.0  2736       0        0        0       0        0        0    0   \n",
      "\n",
      "Status  Vesting  arbitration-bypassed  \n",
      "Year                                   \n",
      "2025.0        1                     1  \n",
      "2026.0        2                     0  \n",
      "2027.0        1                     0  \n",
      "2028.0        2                     0  \n",
      "2029.0        1                     0  \n",
      "2030.0        1                     0  \n",
      "2031.0        1                     0  \n",
      "2032.0        1                     0  \n",
      "2033.0        0                     0  \n",
      "2034.0        0                     0  \n",
      "2035.0        0                     0  \n",
      "2036.0        0                     0  \n",
      "2037.0        0                     0  \n",
      "2038.0        0                     0  \n",
      "2039.0        0                     0  \n",
      "\n",
      "[15 rows x 98 columns]\n",
      "2025-01-11 20:07:00,297 - INFO - Generated 32041 timeline records\n"
     ]
    }
   ],
   "source": [
    "def generate_contract_timeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate timeline until each player's FA year, preserving multiple roles.\"\"\"\n",
    "    logger.info(\"Generating contract timeline\")\n",
    "    \n",
    "    # Create base data without dropping duplicates\n",
    "    base_data = df.groupby('IDfg').apply(\n",
    "        lambda x: [row.to_dict() for _, row in x.iterrows()]\n",
    "    ).to_dict()\n",
    "    \n",
    "    all_rows = []\n",
    "    years = range(2025, 2040)\n",
    "    \n",
    "    for idfg, player_records in base_data.items():\n",
    "        fa_year = player_records[0].get('FA_Year')  # Use first FA year\n",
    "        if pd.isna(fa_year):\n",
    "            continue\n",
    "            \n",
    "        for year in years:\n",
    "            # Check existing records for this year\n",
    "            year_records = [\n",
    "                record for record in player_records \n",
    "                if record.get('Year') == year\n",
    "            ]\n",
    "            \n",
    "            # Use existing records if present\n",
    "            if year_records:\n",
    "                all_rows.extend(year_records)\n",
    "                continue\n",
    "                \n",
    "            # Generate new records based on each role\n",
    "            for base_record in player_records:\n",
    "                new_row = base_record.copy()\n",
    "                new_row['Year'] = year\n",
    "                \n",
    "                # Calculate status\n",
    "                years_to_fa = fa_year - year\n",
    "                if years_to_fa <= 0:\n",
    "                    new_row['Status'] = 'FA'\n",
    "                elif years_to_fa <= 1:\n",
    "                    new_row['Status'] = 'ARB3'\n",
    "                elif years_to_fa <= 2:\n",
    "                    new_row['Status'] = 'ARB2'\n",
    "                elif years_to_fa <= 3:\n",
    "                    new_row['Status'] = 'ARB1'\n",
    "                else:\n",
    "                    new_row['Status'] = 'Pre-ARB'\n",
    "                \n",
    "                new_row['Payroll'] = None\n",
    "                all_rows.append(new_row)\n",
    "    \n",
    "    result = pd.DataFrame(all_rows)\n",
    "    \n",
    "    # Debug status distribution\n",
    "    logger.info(\"\\nStatus Distribution by Year:\")\n",
    "    logger.info(result.groupby(['Year', 'Status']).size().unstack(fill_value=0))\n",
    "    \n",
    "    return result.sort_values(['IDfg', 'Year'])\n",
    "\n",
    "# Execute timeline generation\n",
    "try:\n",
    "    contract_timeline = generate_contract_timeline(contract_data)\n",
    "    logger.info(f\"Generated {len(contract_timeline)} timeline records\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Timeline generation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:07:00,846 - INFO - Processed 32149 rows\n",
      "2025-01-11 20:07:00,848 - INFO - Average WAR value: $7,033,080.07\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WAR Value Calculation Module\n",
    "Applies tiered WAR values and inflation adjustments\n",
    "\"\"\"\n",
    "\n",
    "# Constants\n",
    "WAR_VALUE_TIERS = {\n",
    "    'tier1': {'max': 2, 'value': 8_000_000},\n",
    "    'tier2': {'max': 4, 'value': 9_000_000},\n",
    "    'tier3': {'value': 10_000_000}\n",
    "}\n",
    "INFLATION_RATE = 0.04\n",
    "BASE_YEAR = 2025\n",
    "\n",
    "def calculate_inflation_multiplier(year: int) -> float:\n",
    "    \"\"\"Calculate inflation multiplier from base year.\"\"\"\n",
    "    return (1 + INFLATION_RATE) ** (year - BASE_YEAR)\n",
    "\n",
    "def calculate_war_value(war: float, year: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate WAR value using tiered system and inflation.\n",
    "    \n",
    "    Args:\n",
    "        war (float): WAR value\n",
    "        year (int): Year for inflation adjustment\n",
    "    \"\"\"\n",
    "    if pd.isna(war) or war <= 0:\n",
    "        return 0.0\n",
    "        \n",
    "    value = 0.0\n",
    "    remaining_war = war\n",
    "    \n",
    "    # Tier 1: 0-2 WAR\n",
    "    tier1_war = min(remaining_war, WAR_VALUE_TIERS['tier1']['max'])\n",
    "    value += tier1_war * WAR_VALUE_TIERS['tier1']['value']\n",
    "    remaining_war -= tier1_war\n",
    "    \n",
    "    if remaining_war <= 0:\n",
    "        return value * calculate_inflation_multiplier(year)\n",
    "        \n",
    "    # Tier 2: 2-4 WAR\n",
    "    tier2_war = min(remaining_war, WAR_VALUE_TIERS['tier2']['max'] - WAR_VALUE_TIERS['tier1']['max'])\n",
    "    value += tier2_war * WAR_VALUE_TIERS['tier2']['value']\n",
    "    remaining_war -= tier2_war\n",
    "    \n",
    "    if remaining_war <= 0:\n",
    "        return value * calculate_inflation_multiplier(year)\n",
    "        \n",
    "    # Tier 3: 4+ WAR\n",
    "    value += remaining_war * WAR_VALUE_TIERS['tier3']['value']\n",
    "    \n",
    "    return value * calculate_inflation_multiplier(year)\n",
    "\n",
    "try:\n",
    "    # Join predictions with timeline\n",
    "    timeline_with_war = contract_timeline.merge(\n",
    "        player_predictions[['IDfg', 'prediction_year', 'WAR']],\n",
    "        left_on=['IDfg', 'Year'],\n",
    "        right_on=['IDfg', 'prediction_year'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate WAR values\n",
    "    timeline_with_war['Base_Value'] = timeline_with_war.apply(\n",
    "        lambda x: calculate_war_value(x['WAR'], x['Year']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Clean up and validate\n",
    "    timeline_with_war = timeline_with_war.drop('prediction_year', axis=1)\n",
    "    \n",
    "    logger.info(f\"Processed {len(timeline_with_war)} rows\")\n",
    "    logger.info(f\"Average WAR value: ${timeline_with_war['Base_Value'].mean():,.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to calculate WAR values: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:07:01,472 - INFO - \n",
      "Contract Value Calculation Summary:\n",
      "2025-01-11 20:07:01,473 - INFO - Total rows processed: 32149\n",
      "2025-01-11 20:07:01,475 - INFO - Rows with contract values: 4025\n",
      "2025-01-11 20:07:01,475 - INFO - \n",
      "Contract values by status:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      count          mean           std         min  \\\n",
      "Status                                                                \n",
      "$1,250,000              1.0  1.250000e+06           NaN   1250000.0   \n",
      "$1,750,000              1.0  1.750000e+06           NaN   1750000.0   \n",
      "$1,800,000              1.0  1.800000e+06           NaN   1800000.0   \n",
      "$10,000,000             2.0  1.750000e+07  1.060660e+07  10000000.0   \n",
      "$10,750,000             1.0  1.075000e+07           NaN  10750000.0   \n",
      "...                     ...           ...           ...         ...   \n",
      "Pre-ARB                 6.0  7.637760e+05  1.640539e+04    748800.0   \n",
      "Pre-Arb                 3.0  3.430555e+06  1.929456e+06   2000000.0   \n",
      "UFA                     0.0           NaN           NaN         NaN   \n",
      "Vesting                10.0  1.753333e+07  4.795059e+06  10000000.0   \n",
      "arbitration-bypassed    1.0  8.400000e+06           NaN   8400000.0   \n",
      "\n",
      "                             25%         50%          75%         max  \n",
      "Status                                                                 \n",
      "$1,250,000             1250000.0   1250000.0   1250000.00   1250000.0  \n",
      "$1,750,000             1750000.0   1750000.0   1750000.00   1750000.0  \n",
      "$1,800,000             1800000.0   1800000.0   1800000.00   1800000.0  \n",
      "$10,000,000           13750000.0  17500000.0  21250000.00  25000000.0  \n",
      "$10,750,000           10750000.0  10750000.0  10750000.00  10750000.0  \n",
      "...                          ...         ...          ...         ...  \n",
      "Pre-ARB                 748800.0    763776.0    778752.00    778752.0  \n",
      "Pre-Arb                2333333.0   2666666.0   4145833.00   5625000.0  \n",
      "UFA                          NaN         NaN          NaN         NaN  \n",
      "Vesting               14250000.0  17000000.0  19583333.25  25000000.0  \n",
      "arbitration-bypassed   8400000.0   8400000.0   8400000.00   8400000.0  \n",
      "\n",
      "[98 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Contract Value Calculator\n",
    "Determines player contract values based on:\n",
    "1. Existing payroll data (if available)\n",
    "2. Contract status (Pre-ARB, ARB1-3, FA)\n",
    "3. WAR-based market value\n",
    "\"\"\"\n",
    "\n",
    "# Contract value constants\n",
    "MIN_SALARY = {\n",
    "    'Pre-ARB': 720000,\n",
    "    'ARB1': 1000000,\n",
    "    'ARB2': 2500000,\n",
    "    'ARB3': 4000000\n",
    "}\n",
    "\n",
    "ARB_PERCENT = {\n",
    "    'ARB1': 0.25,\n",
    "    'ARB2': 0.33,\n",
    "    'ARB3': 0.50\n",
    "}\n",
    "\n",
    "def normalize_status(status: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize contract status strings for consistent processing.\n",
    "    \n",
    "    Args:\n",
    "        status: Raw contract status string\n",
    "        \n",
    "    Returns:\n",
    "        Normalized status string (Pre-ARB, ARB1-3, FA, or None)\n",
    "    \"\"\"\n",
    "    if pd.isna(status):\n",
    "        return None\n",
    "        \n",
    "    status = str(status).upper().strip()\n",
    "    \n",
    "    # Handle Pre-ARB variations\n",
    "    if 'PRE' in status and 'ARB' in status:\n",
    "        return 'Pre-ARB'\n",
    "    \n",
    "    # Handle ARB variations\n",
    "    if 'ARB' in status:\n",
    "        for i in range(1, 5):\n",
    "            if str(i) in status:\n",
    "                return f'ARB{min(i, 3)}'  # ARB4 counts as ARB3\n",
    "                \n",
    "    # Handle FA variations\n",
    "    if any(x in status for x in ['UFA', 'FA']):\n",
    "        return 'FA'\n",
    "        \n",
    "    return status\n",
    "\n",
    "def calculate_contract_value(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculate player's contract value based on status and market value.\n",
    "    \n",
    "    Logic:\n",
    "    1. Use existing Payroll if available\n",
    "    2. Skip FA calculations\n",
    "    3. Apply ARB percentages or minimum salary\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with Status, Payroll, Base_Value, and Year\n",
    "    \n",
    "    Returns:\n",
    "        Contract value for the given year\n",
    "    \"\"\"\n",
    "    # 1. Check for existing Payroll\n",
    "    if pd.notna(row['Payroll']):\n",
    "        return row['Payroll']\n",
    "    \n",
    "    # 2. Get normalized status\n",
    "    status = normalize_status(row['Status'])\n",
    "    \n",
    "    # 3. Handle status-based calculations\n",
    "    if status == 'FA' or status == 'UFA':\n",
    "        return None\n",
    "        \n",
    "    # 4. Calculate minimum salary with inflation\n",
    "    year_offset = row['Year'] - BASE_YEAR\n",
    "    min_salary = MIN_SALARY.get(\n",
    "        status, \n",
    "        MIN_SALARY['Pre-ARB']\n",
    "    ) * (1 + INFLATION_RATE) ** year_offset\n",
    "    \n",
    "    # 5. Handle Pre-ARB\n",
    "    if status == 'Pre-ARB':\n",
    "        return min_salary\n",
    "        \n",
    "    # 6. Handle ARB years\n",
    "    if status in ARB_PERCENT:\n",
    "        return max(\n",
    "            min_salary,\n",
    "            row['Base_Value'] * ARB_PERCENT[status]\n",
    "        )\n",
    "        \n",
    "    # 7. If status exists but isn't handled above, use existing Payroll\n",
    "    return row['Payroll']\n",
    "\n",
    "try:\n",
    "    # Calculate contract values\n",
    "    timeline_with_values = timeline_with_war.copy()\n",
    "    timeline_with_values['Contract_Value'] = timeline_with_values.apply(\n",
    "        calculate_contract_value, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Calculate surplus value\n",
    "    timeline_with_values['Surplus_Value'] = (\n",
    "        timeline_with_values['Base_Value'] - \n",
    "        timeline_with_values['Contract_Value']\n",
    "    )\n",
    "    \n",
    "    # Validation summary\n",
    "    logger.info(\"\\nContract Value Calculation Summary:\")\n",
    "    logger.info(f\"Total rows processed: {len(timeline_with_values)}\")\n",
    "    logger.info(f\"Rows with contract values: \"\n",
    "               f\"{timeline_with_values['Contract_Value'].notna().sum()}\")\n",
    "    logger.info(\"\\nContract values by status:\")\n",
    "    print(timeline_with_values.groupby('Status')['Contract_Value'].describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to calculate contract values: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:07:02,180 - INFO - \n",
      "Validation Results:\n",
      "2025-01-11 20:07:02,182 - INFO - Missing data:\n",
      "IDfg                  0\n",
      "Year                  0\n",
      "Status              266\n",
      "WAR                  86\n",
      "Base_Value            0\n",
      "Contract_Value    28124\n",
      "Surplus_Value     28124\n",
      "dtype: int64\n",
      "2025-01-11 20:07:02,183 - INFO - Players with invalid progression: 707\n",
      "2025-01-11 20:07:02,184 - INFO - Minimum salary violations: 0\n"
     ]
    }
   ],
   "source": [
    "def validate_salary_timeline(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Validate salary timeline and generate summary statistics.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with calculated values\n",
    "    Returns:\n",
    "        tuple: (missing_data, invalid_progression, min_salary_violations)\n",
    "    \"\"\"\n",
    "    # Data quality checks\n",
    "    validation_cols = ['IDfg', 'Year', 'Status', 'WAR', \n",
    "                      'Base_Value', 'Contract_Value', 'Surplus_Value']\n",
    "    missing_data = df[validation_cols].isnull().sum()\n",
    "    \n",
    "    # Status progression validation\n",
    "    def check_progression(group_df):\n",
    "        ordered_statuses = group_df.sort_values('Year')['Status']\n",
    "        status_sequence = ['Pre-ARB', 'ARB1', 'ARB2', 'ARB3', 'FA']\n",
    "        current_idx = -1\n",
    "        \n",
    "        for status in ordered_statuses:\n",
    "            if status in status_sequence:\n",
    "                new_idx = status_sequence.index(status)\n",
    "                if new_idx <= current_idx:\n",
    "                    return True\n",
    "                current_idx = new_idx\n",
    "        return False\n",
    "    \n",
    "    invalid_progression = df.groupby('IDfg').apply(check_progression)\n",
    "    \n",
    "    # Value thresholds\n",
    "    def check_min_salary(row):\n",
    "        if row['Status'] not in MIN_SALARY:\n",
    "            return False\n",
    "        min_salary = MIN_SALARY[row['Status']] * (1 + INFLATION_RATE) ** (row['Year'] - BASE_YEAR)\n",
    "        return row['Contract_Value'] < min_salary\n",
    "    \n",
    "    min_salary_violations = df[df.apply(check_min_salary, axis=1)]\n",
    "    \n",
    "    # Log validation results\n",
    "    logger.info(\"\\nValidation Results:\")\n",
    "    logger.info(f\"Missing data:\\n{missing_data}\")\n",
    "    logger.info(f\"Players with invalid progression: {invalid_progression.sum()}\")\n",
    "    logger.info(f\"Minimum salary violations: {len(min_salary_violations)}\")\n",
    "    \n",
    "    return missing_data, invalid_progression, min_salary_violations\n",
    "\n",
    "try:\n",
    "    validation_results = validate_salary_timeline(timeline_with_values)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Validation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:07:09,046 - INFO - Cleaned timeline data shape: (10620, 11)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clean duplicate IDfg/Year pairs from timeline data\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Sort by number of non-null values (keep rows with most data)\n",
    "    timeline_with_values = (timeline_with_values\n",
    "        .loc[timeline_with_values\n",
    "             .groupby(['IDfg', 'Year'])\n",
    "             .apply(lambda x: x.isnull().sum(axis=1).idxmin())]\n",
    "        .reset_index(drop=True))\n",
    "    \n",
    "    # Verify uniqueness\n",
    "    duplicate_check = timeline_with_values.groupby(['IDfg', 'Year']).size()\n",
    "    if (duplicate_check > 1).any():\n",
    "        raise ValueError(\"Duplicates still exist after cleaning\")\n",
    "        \n",
    "    logger.info(f\"Cleaned timeline data shape: {timeline_with_values.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to clean duplicates: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 two-way players\n",
      "Records processed: 10620\n",
      "Columns: ['Player Name', 'Year', 'Team', 'Payroll', 'Status', 'IDfg', 'FA_Year', 'WAR', 'Base_Value', 'Contract_Value', 'Surplus_Value', 'Two_Way', 'Position', 'WAR_batter', 'BB%_bat', 'K%_bat', 'AVG', 'OBP', 'SLG', 'wOBA', 'wRC+', 'EV', 'Off', 'BsR', 'Def', 'WAR_pitcher', 'ERA', 'FIP', 'SIERA', 'K%_pit', 'BB%_pit', 'Age']\n"
     ]
    }
   ],
   "source": [
    "def integrate_player_statistics(value_data, batter_data, sp_data, rp_data):\n",
    "    \"\"\"Integrate stats with combined positions for two-way players\"\"\"\n",
    "    \n",
    "    # Identify two-way players\n",
    "    batter_ids = set(batter_data['IDfg'].unique())\n",
    "    pitcher_ids = set(sp_data['IDfg'].unique()) | set(rp_data['IDfg'].unique())\n",
    "    two_way_players = batter_ids.intersection(pitcher_ids)\n",
    "    print(f\"Found {len(two_way_players)} two-way players\")\n",
    "    \n",
    "    # Start with value data\n",
    "    result = value_data.copy()\n",
    "    result['Two_Way'] = result['IDfg'].isin(two_way_players)\n",
    "    \n",
    "    # Create position mapping\n",
    "    batter_positions = batter_data[['IDfg', 'prediction_year', 'Position']]\\\n",
    "        .rename(columns={'prediction_year': 'Year'})\n",
    "    \n",
    "    pitcher_positions = pd.concat([\n",
    "        sp_data[['IDfg', 'prediction_year', 'Position']],\n",
    "        rp_data[['IDfg', 'prediction_year', 'Position']]\n",
    "    ]).rename(columns={'prediction_year': 'Year'})\n",
    "    \n",
    "    # Merge positions\n",
    "    result = result.merge(batter_positions, on=['IDfg', 'Year'], how='left', suffixes=('', '_batter'))\n",
    "    result = result.merge(pitcher_positions, on=['IDfg', 'Year'], how='left', suffixes=('', '_pitcher'))\n",
    "    \n",
    "    # Combine positions for two-way players\n",
    "    mask = result['Two_Way']\n",
    "    result.loc[mask, 'Position'] = (\n",
    "        result.loc[mask].apply(\n",
    "            lambda x: f\"{x['Position_pitcher']}/{x['Position']}\" if pd.notna(x['Position_pitcher']) else x['Position'],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Use single position for non-two-way players\n",
    "    result.loc[~mask, 'Position'] = result.loc[~mask, 'Position'].fillna(result.loc[~mask, 'Position_pitcher'])\n",
    "    \n",
    "    # Drop temporary position columns\n",
    "    result = result.drop(['Position_batter', 'Position_pitcher'], axis=1, errors='ignore')\n",
    "    \n",
    "    # Merge stats as before\n",
    "    batter_stats = (batter_data[['IDfg', 'prediction_year', 'WAR'] + \n",
    "                   [col for col in HITTER_COLUMNS if col not in ['Name', 'IDfg', 'WAR', 'Position']]]\\\n",
    "                   .rename(columns={\n",
    "                       'prediction_year': 'Year',\n",
    "                       'BB%': 'BB%_bat',\n",
    "                       'K%': 'K%_bat',\n",
    "                       'Age': 'Age_bat',\n",
    "                       'WAR': 'WAR_batter'\n",
    "                   }))\n",
    "    \n",
    "    pitcher_stats = (pd.concat([\n",
    "        sp_data[['IDfg', 'prediction_year', 'WAR'] + \n",
    "                [col for col in PITCHER_COLUMNS if col not in ['Name', 'IDfg', 'WAR', 'Position']]],\n",
    "        rp_data[['IDfg', 'prediction_year', 'WAR'] + \n",
    "                [col for col in PITCHER_COLUMNS if col not in ['Name', 'IDfg', 'WAR', 'Position']]]\n",
    "    ])\\\n",
    "    .rename(columns={\n",
    "        'prediction_year': 'Year',\n",
    "        'BB%': 'BB%_pit',\n",
    "        'K%': 'K%_pit',\n",
    "        'Age': 'Age_pit',\n",
    "        'WAR': 'WAR_pitcher'\n",
    "    })\\\n",
    "    .drop_duplicates(subset=['IDfg', 'Year']))\n",
    "    \n",
    "    # Merge stats while preserving Position\n",
    "    result = result.merge(batter_stats, on=['IDfg', 'Year'], how='left')\n",
    "    result = result.merge(pitcher_stats, on=['IDfg', 'Year'], how='left')\n",
    "    \n",
    "    # Handle WAR values\n",
    "    result.loc[mask, 'WAR'] = (\n",
    "        result.loc[mask, 'WAR_batter'].fillna(0) + \n",
    "        result.loc[mask, 'WAR_pitcher'].fillna(0)\n",
    "    )\n",
    "    result.loc[~mask, 'WAR'] = result.loc[~mask, 'WAR_batter'].fillna(result.loc[~mask, 'WAR_pitcher'])\n",
    "    \n",
    "    # Combine ages\n",
    "    result['Age'] = result['Age_bat'].fillna(result['Age_pit'])\n",
    "    result = result.drop(['Age_bat', 'Age_pit'], axis=1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Execute\n",
    "try:\n",
    "    export_data = integrate_player_statistics(\n",
    "        timeline_with_values,\n",
    "        batter_data,\n",
    "        sp_data, \n",
    "        rp_data\n",
    "    )\n",
    "    print(f\"Records processed: {len(export_data)}\")\n",
    "    print(f\"Columns: {export_data.columns.tolist()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:07:09,191 - INFO - Starting value data export\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 20:07:09,234 - INFO - Exported 708 records for 2025.0\n",
      "2025-01-11 20:07:09,263 - INFO - Exported 708 records for 2026.0\n",
      "2025-01-11 20:07:09,306 - INFO - Exported 708 records for 2027.0\n",
      "2025-01-11 20:07:09,336 - INFO - Exported 708 records for 2028.0\n",
      "2025-01-11 20:07:09,378 - INFO - Exported 708 records for 2029.0\n",
      "2025-01-11 20:07:09,411 - INFO - Exported 708 records for 2030.0\n",
      "2025-01-11 20:07:09,434 - INFO - Exported 708 records for 2031.0\n",
      "2025-01-11 20:07:09,456 - INFO - Exported 708 records for 2032.0\n",
      "2025-01-11 20:07:09,476 - INFO - Exported 708 records for 2033.0\n",
      "2025-01-11 20:07:09,497 - INFO - Exported 708 records for 2034.0\n",
      "2025-01-11 20:07:09,520 - INFO - Exported 708 records for 2035.0\n",
      "2025-01-11 20:07:09,540 - INFO - Exported 708 records for 2036.0\n",
      "2025-01-11 20:07:09,568 - INFO - Exported 708 records for 2037.0\n",
      "2025-01-11 20:07:09,590 - INFO - Exported 708 records for 2038.0\n",
      "2025-01-11 20:07:09,611 - INFO - Exported 708 records for 2039.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status Distribution:\n",
      "Status  $1,250,000  $1,750,000  $1,800,000  $10,000,000  $10,750,000  \\\n",
      "Year                                                                   \n",
      "2025.0           1           1           1            1            1   \n",
      "2026.0           0           0           0            0            0   \n",
      "2027.0           0           0           0            0            0   \n",
      "2028.0           0           0           0            0            0   \n",
      "2029.0           0           0           0            1            0   \n",
      "2030.0           0           0           0            0            0   \n",
      "2031.0           0           0           0            0            0   \n",
      "2032.0           0           0           0            0            0   \n",
      "2033.0           0           0           0            0            0   \n",
      "2034.0           0           0           0            0            0   \n",
      "2035.0           0           0           0            0            0   \n",
      "2036.0           0           0           0            0            0   \n",
      "2037.0           0           0           0            0            0   \n",
      "2038.0           0           0           0            0            0   \n",
      "2039.0           0           0           0            0            0   \n",
      "\n",
      "Status  $12,000,000  $12,500,000  $13,000,000  $13,142,857  $14,500,000  ...  \\\n",
      "Year                                                                     ...   \n",
      "2025.0            1            0            2            1            1  ...   \n",
      "2026.0            0            0            0            1            1  ...   \n",
      "2027.0            0            0            0            0            0  ...   \n",
      "2028.0            0            1            0            0            0  ...   \n",
      "2029.0            0            0            0            0            0  ...   \n",
      "2030.0            0            0            0            0            0  ...   \n",
      "2031.0            0            0            0            0            0  ...   \n",
      "2032.0            0            0            0            0            0  ...   \n",
      "2033.0            0            0            0            0            0  ...   \n",
      "2034.0            0            0            0            0            0  ...   \n",
      "2035.0            0            0            0            0            0  ...   \n",
      "2036.0            0            0            0            0            0  ...   \n",
      "2037.0            0            0            0            0            0  ...   \n",
      "2038.0            0            0            0            0            0  ...   \n",
      "2039.0            0            0            0            0            0  ...   \n",
      "\n",
      "Status   FA  Mutual  Opt-Out  PRE-ARB  Player  Pre-ARB  Pre-Arb  UFA  Vesting  \\\n",
      "Year                                                                            \n",
      "2025.0    0       0        3        0       9        0        3    0        1   \n",
      "2026.0    0       5        5      198       5        3        0   81        2   \n",
      "2027.0   82       3        2      114       3        3        0  106        1   \n",
      "2028.0  190       0        0        0       1        0        0  102        2   \n",
      "2029.0  410       1        0        0       0        0        0   53        1   \n",
      "2030.0  547       0        2        0       0        0        0    6        1   \n",
      "2031.0  670       0        1        0       0        0        0   12        1   \n",
      "2032.0  682       0        2        0       0        0        0    8        1   \n",
      "2033.0  690       0        1        0       0        0        0    5        0   \n",
      "2034.0  695       0        1        0       0        0        0    8        0   \n",
      "2035.0  703       0        0        0       0        0        0    2        0   \n",
      "2036.0  705       0        0        0       0        0        0    1        0   \n",
      "2037.0  706       0        0        0       0        0        0    0        0   \n",
      "2038.0  706       0        0        0       0        0        0    1        0   \n",
      "2039.0  707       0        0        0       0        0        0    0        0   \n",
      "\n",
      "Status  arbitration-bypassed  \n",
      "Year                          \n",
      "2025.0                     1  \n",
      "2026.0                     0  \n",
      "2027.0                     0  \n",
      "2028.0                     0  \n",
      "2029.0                     0  \n",
      "2030.0                     0  \n",
      "2031.0                     0  \n",
      "2032.0                     0  \n",
      "2033.0                     0  \n",
      "2034.0                     0  \n",
      "2035.0                     0  \n",
      "2036.0                     0  \n",
      "2037.0                     0  \n",
      "2038.0                     0  \n",
      "2039.0                     0  \n",
      "\n",
      "[15 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Value Export Module\n",
    "Exports yearly player valuations sorted by team and WAR\n",
    "\"\"\"\n",
    "\n",
    "def export_value_data(df: pd.DataFrame, output_dir: Path) -> None:\n",
    "    \"\"\"Export sorted value data by year.\"\"\"\n",
    "    logger.info(\"Starting value data export\")\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Define column groups\n",
    "    base_cols = [\n",
    "        'Player Name', 'Team', 'Status', 'Position', 'Age', 'WAR',\n",
    "        'Base_Value', 'Contract_Value', 'Surplus_Value', 'IDfg'\n",
    "    ]\n",
    "    \n",
    "    hitting_cols = [\n",
    "        'BB%_bat', 'K%_bat', 'AVG', 'OBP', 'SLG',\n",
    "        'wOBA', 'wRC+', 'EV', 'Off', 'BsR', 'Def', 'WAR_batter'\n",
    "    ]\n",
    "    \n",
    "    pitching_cols = [\n",
    "        'ERA', 'FIP', 'SIERA', 'K%_pit', 'BB%_pit', 'WAR_pitcher'\n",
    "    ]\n",
    "    \n",
    "    export_cols = base_cols + hitting_cols + pitching_cols\n",
    "    \n",
    "    for year in sorted(df['Year'].unique()):\n",
    "        try:\n",
    "            # Get year's data and sort\n",
    "            year_data = df[df['Year'] == year].copy()\n",
    "            \n",
    "            # Sort data\n",
    "            year_data = year_data.sort_values(['Team', 'WAR'], ascending=[True, False])\n",
    "            \n",
    "            # Format numeric columns\n",
    "            numeric_cols = ['Base_Value', 'Contract_Value', 'Surplus_Value']\n",
    "            for col in numeric_cols:\n",
    "                if col in year_data.columns:\n",
    "                    year_data[col] = year_data[col].round(2)\n",
    "            \n",
    "            # Export with all columns\n",
    "            output_file = output_dir / f'player_values_{year}.csv'\n",
    "            year_data.to_csv(output_file, columns=export_cols, index=False, na_rep='')\n",
    "            \n",
    "            logger.info(f\"Exported {len(year_data)} records for {year}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing year {year}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "try:\n",
    "   \n",
    "    # Execute export\n",
    "    export_value_data(export_data, OUTPUT_DIR)\n",
    "    \n",
    "    # Print status distribution\n",
    "    print(\"\\nStatus Distribution:\")\n",
    "    print(export_data.groupby(['Year', 'Status']).size().unstack(fill_value=0))\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Export process failed: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

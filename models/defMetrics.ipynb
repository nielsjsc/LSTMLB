{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "class DefensiveDataLogger:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "    \n",
    "    def log(self, stage: str, message: str):\n",
    "        self.logs.append(f\"{stage}: {message}\")\n",
    "\n",
    "logger = DefensiveDataLogger()\n",
    "@dataclass\n",
    "class DefensiveDataConfig:\n",
    "    seq_length: int = 3\n",
    "    min_seq_length: int = 1\n",
    "    min_innings: int = 100\n",
    "    train_ratio: float = 0.7\n",
    "    valid_ratio: float = 0.2\n",
    "    rate_scaling: int = 150\n",
    "    batch_size: int = 32\n",
    "    position_map: Dict[str, int] = field(default_factory=lambda: {\n",
    "        'C': 0, '1B': 1, '2B': 2, '3B': 3, 'SS': 4,\n",
    "        'LF': 5, 'CF': 6, 'RF': 7, 'DH': 8\n",
    "    })\n",
    "@dataclass\n",
    "class DefensiveMetrics:\n",
    "    \"\"\"Container for defensive rate metrics.\"\"\"\n",
    "    drs_150: float\n",
    "    uzr_150: float\n",
    "    oaa_150: float\n",
    "    inn: float\n",
    "    age: int\n",
    "    position: str = ''  # Add position field\n",
    "    def to_tensor(self) -> torch.Tensor:\n",
    "        return torch.tensor([\n",
    "            self.drs_150,\n",
    "            self.uzr_150,\n",
    "            self.oaa_150,\n",
    "            self.age\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "@dataclass\n",
    "class DefensiveSequence:\n",
    "    player_id: str\n",
    "    position: str  # Add this\n",
    "    history: List[Optional[DefensiveMetrics]]\n",
    "    target: Optional[DefensiveMetrics]\n",
    "    history_mask: List[bool]\n",
    "\n",
    "class DefensiveDataProcessor:\n",
    "    \"\"\"Process fielding data into defensive sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DefensiveDataConfig):\n",
    "        self.config = config\n",
    "        self.metric_scaler = StandardScaler()\n",
    "    def filter_complete_records(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Filter records with complete defensive metrics.\"\"\"\n",
    "        complete_mask = df[['DRS', 'UZR/150', 'OAA', 'Inn']].notna().all(axis=1)\n",
    "        logger.log(\"Data Filter\", f\"Complete records: {complete_mask.sum()} of {len(df)}\")\n",
    "        return df[complete_mask].copy()\n",
    "\n",
    "    def prepare_data(self, df: pd.DataFrame, add_age: bool = False, current_age: int = None) -> pd.DataFrame:\n",
    "        \"\"\"Prepare dataframe with enhanced filtering.\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Add age if needed\n",
    "        if add_age and current_age is not None:\n",
    "            df['Age'] = current_age\n",
    "        \n",
    "        # Initial data state\n",
    "        logger.log(\"Data Prep\", f\"Initial records: {len(df)}\")\n",
    "        \n",
    "        # Validate positions\n",
    "        valid_positions = set(self.config.position_map.keys())\n",
    "        position_mask = df['Pos'].isin(valid_positions)\n",
    "        df = df[position_mask].copy()\n",
    "        logger.log(\"Data Prep\", f\"After position filter: {len(df)}\")\n",
    "        \n",
    "        # Filter complete records first\n",
    "        df = self.filter_complete_records(df)\n",
    "        logger.log(\"Data Prep\", f\"After complete filter: {len(df)}\")\n",
    "        \n",
    "        # Filter innings\n",
    "        df = df[df['Inn'] >= self.config.min_innings].copy()\n",
    "        logger.log(\"Data Prep\", f\"After innings filter: {len(df)}\")\n",
    "        \n",
    "        # Calculate rate stats\n",
    "        df = self.calculate_rate_stats(df)\n",
    "        \n",
    "        # Validate final dataset\n",
    "        final_mask = df[['drs_150', 'uzr_150', 'oaa_150', 'Age', 'Pos']].notna().all(axis=1)\n",
    "        df = df[final_mask].copy()\n",
    "        \n",
    "        # Add position encoding\n",
    "        df['position_idx'] = df['Pos'].map(self.config.position_map)\n",
    "        \n",
    "        logger.log(\"Data Prep\", f\"Final records: {len(df)}\")\n",
    "        logger.log(\"Data Prep\", f\"Position distribution:\\n{df['Pos'].value_counts()}\")\n",
    "        \n",
    "        return df\n",
    "    def _validate_sequence_quality(self, history: pd.DataFrame) -> bool:\n",
    "        \"\"\"Check if all seasons meet minimum innings requirement.\"\"\"\n",
    "        return all(history['Inn'] >= self.config.min_innings)\n",
    "    def validate_defensive_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Validate and clean defensive metrics data.\"\"\"\n",
    "\n",
    "        \n",
    "        # Check for infinities and NaN\n",
    "        inf_mask = df.isin([np.inf, -np.inf]).any(axis=1)\n",
    "        nan_mask = df.isna().any(axis=1)\n",
    "        \n",
    "        # Remove problematic rows\n",
    "        df = df[~inf_mask & ~nan_mask].copy()\n",
    "        \n",
    "        # Report on defensive metrics\n",
    "        metrics = ['DRS', 'UZR/150', 'OAA']\n",
    "        print(\"\\nMetric Statistics:\")\n",
    "        for metric in metrics:\n",
    "            stats = df[metric].describe()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _validate_sequence(self, history_mask: List[bool]) -> Tuple[bool, int, int]:\n",
    "        \"\"\"\n",
    "        Validates if sequence has continuous valid seasons.\n",
    "        Returns (is_valid, start_idx, length)\n",
    "        \"\"\"\n",
    "        current_length = 0\n",
    "        max_length = 0\n",
    "        start_idx = 0\n",
    "        best_start = 0\n",
    "        \n",
    "        for i, mask in enumerate(history_mask):\n",
    "            if mask:\n",
    "                if current_length == 0:\n",
    "                    start_idx = i\n",
    "                current_length += 1\n",
    "                if current_length > max_length:\n",
    "                    max_length = current_length\n",
    "                    best_start = start_idx\n",
    "            else:\n",
    "                current_length = 0\n",
    "                \n",
    "        return max_length >= self.config.min_seq_length, best_start, max_length\n",
    "    def calculate_rate_stats(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate rate stats per 150 games with empty data handling.\"\"\"\n",
    "        EPSILON = 1e-7\n",
    "        rate_df = df.copy()\n",
    "        \n",
    "        # Early return if DataFrame is empty\n",
    "        if len(df) == 0:\n",
    "            logger.log(\"Rate Stats\", \"Empty DataFrame received\")\n",
    "            return rate_df\n",
    "        \n",
    "        # Convert innings to games\n",
    "        games = df['Inn'] / 9.0  # 9 innings per game\n",
    "        \n",
    "        # Calculate rates per 150 games\n",
    "        rate_df['drs_150'] = (df['DRS'] / (games + EPSILON)) * 150\n",
    "        rate_df['uzr_150'] = df['UZR/150']  # Already a rate stat\n",
    "        rate_df['oaa_150'] = (df['OAA'] / (games + EPSILON)) * 150\n",
    "        \n",
    "        # Only clip if we have data\n",
    "        if len(rate_df) > 0:\n",
    "            for col in ['drs_150', 'uzr_150', 'oaa_150']:\n",
    "                if not rate_df[col].empty:\n",
    "                    low, high = np.percentile(rate_df[col].dropna(), [1, 99])\n",
    "                    rate_df[col] = rate_df[col].clip(low, high)\n",
    "                    logger.log(\"Rate Stats\", f\"{col} range: {low:.2f} to {high:.2f}\")\n",
    "        \n",
    "        return rate_df\n",
    "    def create_prediction_sequence(self, df: pd.DataFrame, current_age: int) -> List[DefensiveSequence]:\n",
    "        \"\"\"Create sequence for prediction with age handling.\"\"\"\n",
    "        prepared_df = self.prepare_data(df, add_age=True, current_age=current_age)\n",
    "        prepared_df = prepared_df.sort_values('Season')\n",
    "        position = prepared_df['Pos'].iloc[0]  # Get position\n",
    "        \n",
    "        history_metrics = []\n",
    "        history_mask = []\n",
    "        \n",
    "        for _, season in prepared_df.iterrows():\n",
    "            metrics = DefensiveMetrics(\n",
    "                drs_150=season['drs_150'],\n",
    "                uzr_150=season['uzr_150'],\n",
    "                oaa_150=season['oaa_150'],\n",
    "                inn=season['Inn'],\n",
    "                age=season['Age'],\n",
    "                position=position  # Add position\n",
    "            )\n",
    "            history_metrics.append(metrics)\n",
    "            history_mask.append(season['Inn'] >= self.config.min_innings)\n",
    "        \n",
    "        return [DefensiveSequence(\n",
    "            player_id=str(prepared_df['IDfg'].iloc[0]),\n",
    "            position=position,  # Add position\n",
    "            history=history_metrics,\n",
    "            target=None,\n",
    "            history_mask=history_mask\n",
    "        )]\n",
    "    def _get_metrics(self, player_data: pd.DataFrame, season: int) -> Optional[DefensiveMetrics]:\n",
    "        \"\"\"Extract defensive metrics for a given season.\"\"\"\n",
    "        season_data = player_data[player_data['Season'] == season]\n",
    "        if len(season_data) != 1:\n",
    "            return None\n",
    "            \n",
    "        row = season_data.iloc[0]\n",
    "        if pd.isna([row['drs_150'], row['uzr_150'], row['oaa_150'], row['Age']]).any():\n",
    "            return None\n",
    "            \n",
    "        return DefensiveMetrics(\n",
    "            drs_150=row['drs_150'],\n",
    "            uzr_150=row['uzr_150'],\n",
    "            oaa_150=row['oaa_150'],\n",
    "            inn=row['Inn'],\n",
    "            age=row['Age'],\n",
    "            position=row['Pos']\n",
    "        )\n",
    "    def create_sequences(self, fielding_df: pd.DataFrame) -> List[DefensiveSequence]:\n",
    "        \"\"\"Create sequences allowing for missing seasons.\"\"\"\n",
    "        prepared_df = self.prepare_data(fielding_df)\n",
    "        sequences = []\n",
    "        \n",
    "        # Group by player and position\n",
    "        for (player_id, position), player_data in prepared_df.groupby(['IDfg', 'Pos']):\n",
    "            player_data = player_data.sort_values('Season')\n",
    "            seasons = player_data['Season'].unique()\n",
    "            \n",
    "            if len(seasons) < 2:  # Need at least one history and one target\n",
    "                continue\n",
    "                \n",
    "            for target_idx in range(1, len(seasons)):\n",
    "                target_season = seasons[target_idx]\n",
    "                history_seasons = seasons[:target_idx]\n",
    "                \n",
    "                # Get up to 3 most recent history seasons\n",
    "                history_seasons = history_seasons[-3:]\n",
    "                \n",
    "                # Get metrics for each season\n",
    "                history = []\n",
    "                history_mask = []\n",
    "                \n",
    "                for season in history_seasons:\n",
    "                    metrics = self._get_metrics(player_data, season)\n",
    "                    history.append(metrics)\n",
    "                    history_mask.append(metrics is not None)\n",
    "                \n",
    "                target = self._get_metrics(player_data, target_season)\n",
    "                \n",
    "                # Create sequence if we have at least one valid history season and target\n",
    "                if any(history_mask) and target is not None:\n",
    "                    sequences.append(DefensiveSequence(\n",
    "                        player_id=str(player_id),\n",
    "                        position=position,  # Add this\n",
    "                        history=history,\n",
    "                        target=target,\n",
    "                        history_mask=history_mask\n",
    "                    ))\n",
    "        \n",
    "        logger.log(\"Sequences\", f\"Created {len(sequences)} sequences\")\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DefensiveDataset(Dataset):\n",
    "    def __init__(self, sequences: List[DefensiveSequence], config: DefensiveDataConfig):\n",
    "        self.sequences = sequences\n",
    "        self.config = config\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        max_len = self.config.seq_length\n",
    "        \n",
    "        history = torch.zeros(max_len, 4, dtype=torch.float32)\n",
    "        history_mask = torch.zeros(max_len, dtype=torch.bool)\n",
    "        \n",
    "        for i, metrics in enumerate(seq.history):\n",
    "            if metrics is not None:\n",
    "                history[i] = torch.tensor([\n",
    "                    metrics.drs_150,\n",
    "                    metrics.uzr_150,\n",
    "                    metrics.oaa_150,\n",
    "                    metrics.age\n",
    "                ], dtype=torch.float32)\n",
    "                history_mask[i] = True\n",
    "        \n",
    "        return {\n",
    "            'history': history,\n",
    "            'history_mask': history_mask,\n",
    "            'target': torch.tensor([\n",
    "                seq.target.drs_150,\n",
    "                seq.target.uzr_150,\n",
    "                seq.target.oaa_150\n",
    "            ], dtype=torch.float32),\n",
    "            'target_mask': torch.tensor(1.0, dtype=torch.float32),\n",
    "            'position': torch.tensor(self.config.position_map[seq.position])\n",
    "        }\n",
    "\n",
    "def get_data_loaders(train_sequences, valid_sequences, test_sequences, config):\n",
    "    # Create datasets\n",
    "    train_dataset = DefensiveDataset(train_sequences, config)\n",
    "    valid_dataset = DefensiveDataset(valid_sequences, config)\n",
    "    test_dataset = DefensiveDataset(test_sequences, config)\n",
    "    \n",
    "    # Define collate function with position\n",
    "    def collate_fn(batch):\n",
    "        return {\n",
    "            'history': torch.stack([s['history'] for s in batch]).float(),\n",
    "            'history_mask': torch.stack([s['history_mask'] for s in batch]),\n",
    "            'target': torch.stack([s['target'] for s in batch]).float(),\n",
    "            'target_mask': torch.stack([s['target_mask'] for s in batch]).float(),\n",
    "            'position': torch.stack([s['position'] for s in batch])\n",
    "        }\n",
    "    \n",
    "    # Create loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defensive Sequences Split:\n",
      "Train: 2071\n",
      "Valid: 591\n",
      "Test: 297\n"
     ]
    }
   ],
   "source": [
    "# Initialize config and processor\n",
    "defensive_config = DefensiveDataConfig()\n",
    "processor = DefensiveDataProcessor(defensive_config)\n",
    "\n",
    "# Load and prepare data\n",
    "fielding_df = pd.read_csv('../data/mlb_fielding_data_2000_2024.csv')\n",
    "batting_df = pd.read_csv('../data/mlb_batting_data_2000_2024.csv')\n",
    "\n",
    "# Add Age column to fielding_df\n",
    "fielding_df = fielding_df.merge(\n",
    "    batting_df[['IDfg', 'Season', 'Age']], \n",
    "    on=['IDfg', 'Season'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create sequences with position handling\n",
    "sequences = processor.create_sequences(fielding_df)\n",
    "\n",
    "# Split sequences\n",
    "total_size = len(sequences)\n",
    "train_size = int(total_size * defensive_config.train_ratio)\n",
    "valid_size = int(total_size * defensive_config.valid_ratio)\n",
    "\n",
    "train_sequences = sequences[:train_size]\n",
    "valid_sequences = sequences[train_size:train_size + valid_size]\n",
    "test_sequences = sequences[train_size + valid_size:]\n",
    "\n",
    "# Create data loaders with proper collation\n",
    "train_loader, valid_loader, test_loader = get_data_loaders(\n",
    "    train_sequences, \n",
    "    valid_sequences, \n",
    "    test_sequences, \n",
    "    defensive_config\n",
    ")\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"\\nDefensive Sequences Split:\")\n",
    "print(f\"Train: {len(train_loader.dataset)}\")\n",
    "print(f\"Valid: {len(valid_loader.dataset)}\")\n",
    "print(f\"Test: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    hidden_size: int = 64\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.1\n",
    "    embedding_dim: int = 16\n",
    "    input_size: int = 4\n",
    "    output_size: int = 3\n",
    "    num_positions: int = 9  # New: number of positions\n",
    "    attention_heads: int = 4  # New: for attention mechanism\n",
    "\n",
    "class DefensivePredictor(nn.Module):\n",
    "    def __init__(self, model_config: ModelConfig, data_config: DefensiveDataConfig):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Position embedding\n",
    "        self.pos_embedding = nn.Embedding(\n",
    "            model_config.num_positions,\n",
    "            model_config.embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Adjusted input size with position embedding\n",
    "        total_input_size = model_config.input_size + model_config.embedding_dim\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            model_config.hidden_size * 2,\n",
    "            model_config.attention_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=total_input_size,\n",
    "            hidden_size=model_config.hidden_size,\n",
    "            num_layers=model_config.num_layers,\n",
    "            dropout=model_config.dropout,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        lstm_out_size = model_config.hidden_size * 2\n",
    "        \n",
    "        # Predictors with uncertainty\n",
    "        self.metric_predictors = nn.ModuleDict({\n",
    "            metric: nn.Sequential(\n",
    "                nn.Linear(lstm_out_size, model_config.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(model_config.hidden_size, 2)  # mean and variance\n",
    "            ) for metric in ['drs', 'uzr', 'oaa']\n",
    "        })\n",
    "        \n",
    "    def forward(self, history: torch.Tensor, history_mask: torch.Tensor, \n",
    "                positions: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size = history.shape[0]\n",
    "        history = history.float()\n",
    "        positions = positions.long()\n",
    "        # Position embeddings\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        history = torch.cat([history, pos_emb.unsqueeze(1).expand(-1, history.shape[1], -1)], dim=-1)\n",
    "        \n",
    "        \n",
    "        # Mask processing\n",
    "        masked_history = history * history_mask.unsqueeze(-1)\n",
    "        lengths = history_mask.sum(1).clamp(min=1).long().cpu()\n",
    "        \n",
    "        # Pack and process\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            masked_history, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        lstm_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        \n",
    "        # Apply attention\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out, \n",
    "                                   key_padding_mask=~history_mask.bool())\n",
    "        \n",
    "        # Get final states\n",
    "        final_hidden = attn_out[torch.arange(batch_size), lengths - 1]\n",
    "        \n",
    "        # Quality-weighted predictions\n",
    "        valid_ratio = lengths.float() / history.shape[1]\n",
    "        quality_weight = valid_ratio.to(final_hidden.device).unsqueeze(1)\n",
    "        \n",
    "        # Predictions with uncertainty\n",
    "        predictions = []\n",
    "        uncertainties = []\n",
    "        for name in ['drs', 'uzr', 'oaa']:\n",
    "            pred = self.metric_predictors[name](final_hidden)\n",
    "            mean, var = pred.chunk(2, dim=1)\n",
    "            predictions.append(mean * quality_weight)\n",
    "            uncertainties.append(var + (1 - quality_weight))\n",
    "            \n",
    "        return (torch.cat(predictions, dim=1), \n",
    "                torch.cat(uncertainties, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration.\"\"\"\n",
    "    learning_rate: float = 1e-3\n",
    "    epochs: int = 50\n",
    "    patience: int = 5\n",
    "    clip_grad_norm: float = 1.0\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class DefensiveTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: DefensivePredictor,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        training_config: TrainingConfig,\n",
    "    ):\n",
    "        self.model = model.to(training_config.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = training_config\n",
    "        self.device = training_config.device\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            [{'params': model.parameters(), 'clip_grad_norm': 1.0}],\n",
    "            lr=training_config.learning_rate\n",
    "        )\n",
    "        self.criterion = nn.MSELoss(reduction='none')\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            predictions, uncertainties = self.model(\n",
    "                batch['history'],\n",
    "                batch['history_mask'],\n",
    "                batch['position']\n",
    "            )\n",
    "            \n",
    "            loss = self.criterion(predictions, batch['target'])\n",
    "            masked_loss = (loss * batch['target_mask'].unsqueeze(1))\n",
    "            weighted_loss = (masked_loss * torch.exp(-uncertainties) + uncertainties * 0.5).mean()\n",
    "            \n",
    "            weighted_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.clip_grad_norm)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += weighted_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        return epoch_loss / max(num_batches, 1)\n",
    "    \n",
    "    def validate(self) -> float:\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "                \n",
    "                predictions, uncertainties = self.model(\n",
    "                    batch['history'],\n",
    "                    batch['history_mask'],\n",
    "                    batch['position']\n",
    "                )\n",
    "                \n",
    "                loss = self.criterion(predictions, batch['target'])\n",
    "                masked_loss = (loss * batch['target_mask'].unsqueeze(1))\n",
    "                weighted_loss = (masked_loss * torch.exp(-uncertainties) + uncertainties * 0.5).mean()\n",
    "                val_loss += weighted_loss.item()\n",
    "                \n",
    "        return val_loss / len(self.val_loader)\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(self.config.epochs):\n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "            \n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            \n",
    "            print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                if self.patience_counter >= self.config.patience:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 23.9270, Val Loss = 3.4636\n",
      "Epoch 1: Train Loss = 3.3723, Val Loss = 3.4001\n",
      "Epoch 2: Train Loss = 3.3776, Val Loss = 3.4002\n",
      "Epoch 3: Train Loss = 3.3559, Val Loss = 3.4050\n",
      "Epoch 4: Train Loss = 3.3489, Val Loss = 3.4082\n",
      "Epoch 5: Train Loss = 3.3431, Val Loss = 3.4052\n",
      "Epoch 6: Train Loss = 3.3394, Val Loss = 3.4225\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Initialize configs and model\n",
    "model_config = ModelConfig()\n",
    "training_config = TrainingConfig()\n",
    "\n",
    "model = DefensivePredictor(model_config, defensive_config)\n",
    "\n",
    "# Initialize trainer with existing loaders\n",
    "trainer = DefensiveTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,  # Already created by get_data_loaders()\n",
    "    val_loader=valid_loader,    # Already created by get_data_loaders()\n",
    "    training_config=training_config\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict future performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1443 [00:00<00:34, 41.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing player with 4 seasons of data\n",
      "       Season     Inn   DRS  UZR/150   OAA\n",
      "41249    2021  1372.0  -7.0      1.5   3.0\n",
      "43670    2022  1433.0   9.0      1.4  20.0\n",
      "46075    2023  1279.1  18.0      5.7  20.0\n",
      "48368    2024  1273.1   7.0      4.4  18.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m predictions_2024 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_2024_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfielding_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Add player names\u001b[39;00m\n\u001b[0;32m     88\u001b[0m name_map \u001b[38;5;241m=\u001b[39m fielding_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDfg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDfg\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[14], line 64\u001b[0m, in \u001b[0;36mgenerate_2024_predictions\u001b[1;34m(fielding_df, model, processor)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Generate prediction\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_defensive_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_seasons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefensive_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred:\n\u001b[0;32m     66\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mpredict_defensive_metrics\u001b[1;34m(model, player_data, processor, config)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Single prediction\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 18\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m     history \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     20\u001b[0m     history_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m, in \u001b[0;36mDefensiveDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, metrics \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seq\u001b[38;5;241m.\u001b[39mhistory):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m         \u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[0;32m     20\u001b[0m             metrics\u001b[38;5;241m.\u001b[39mdrs_150,\n\u001b[0;32m     21\u001b[0m             metrics\u001b[38;5;241m.\u001b[39muzr_150,\n\u001b[0;32m     22\u001b[0m             metrics\u001b[38;5;241m.\u001b[39moaa_150,\n\u001b[0;32m     23\u001b[0m             metrics\u001b[38;5;241m.\u001b[39mage\n\u001b[0;32m     24\u001b[0m         ], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     25\u001b[0m         history_mask[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: history,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: history_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mposition_map[seq\u001b[38;5;241m.\u001b[39mposition])\n\u001b[0;32m     37\u001b[0m }\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "def predict_defensive_metrics(model, player_data: pd.DataFrame, processor: DefensiveDataProcessor, config: DefensiveDataConfig):\n",
    "    \"\"\"Generate predictions with uncertainty for a player's defensive metrics\"\"\"\n",
    "    # Add logging\n",
    "    print(f\"Processing player with {len(player_data)} seasons of data\")\n",
    "    print(player_data[['Season', 'Inn', 'DRS', 'UZR/150', 'OAA']].to_string())\n",
    "    \n",
    "    sequences = processor.create_prediction_sequence(player_data, current_age=2024 - player_data['Season'].min())\n",
    "    \n",
    "    if not sequences:\n",
    "        print(\"No valid sequences created\")\n",
    "        return None\n",
    "        \n",
    "    # Create mini-dataset\n",
    "    dataset = DefensiveDataset(sequences, config)\n",
    "    \n",
    "    # Single prediction\n",
    "    with torch.no_grad():\n",
    "        batch = dataset[0]\n",
    "        history = batch['history'].unsqueeze(0).to(model.device)\n",
    "        history_mask = batch['history_mask'].unsqueeze(0).to(model.device)\n",
    "        position = batch['position'].unsqueeze(0).to(model.device)\n",
    "        \n",
    "        predictions, uncertainties = model(history, history_mask, position)\n",
    "        \n",
    "    # Convert to numpy\n",
    "    pred_metrics = predictions.cpu().numpy()[0]\n",
    "    pred_uncert = uncertainties.cpu().numpy()[0]\n",
    "    \n",
    "    return {\n",
    "        'drs_150_pred': pred_metrics[0],\n",
    "        'drs_150_uncert': pred_uncert[0],\n",
    "        'uzr_150_pred': pred_metrics[1], \n",
    "        'uzr_150_uncert': pred_uncert[1],\n",
    "        'oaa_150_pred': pred_metrics[2],\n",
    "        'oaa_150_uncert': pred_uncert[2],\n",
    "        'position': sequences[0].position,\n",
    "        'player_id': sequences[0].player_id\n",
    "    }\n",
    "\n",
    "def generate_2024_predictions(fielding_df: pd.DataFrame, model, processor: DefensiveDataProcessor):\n",
    "    \"\"\"Generate predictions for all 2024 players with better filtering\"\"\"\n",
    "    \n",
    "    # Get unique players in 2024\n",
    "    players_2024 = fielding_df[fielding_df['Season'] == 2024]['IDfg'].unique()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for player_id in tqdm(players_2024):\n",
    "        # Get player history (2021-2024)\n",
    "        player_data = fielding_df[\n",
    "            (fielding_df['IDfg'] == player_id) & \n",
    "            (fielding_df['Season'] >= 2021)\n",
    "        ]\n",
    "        \n",
    "        # Verify we have complete defensive metrics\n",
    "        has_metrics = player_data[['DRS', 'UZR/150', 'OAA', 'Inn']].notna().all(axis=1)\n",
    "        valid_seasons = player_data[has_metrics]\n",
    "        \n",
    "        # Skip if insufficient history\n",
    "        if len(valid_seasons) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Generate prediction\n",
    "        pred = predict_defensive_metrics(model, valid_seasons, processor, defensive_config)\n",
    "        if pred:\n",
    "            predictions.append(pred)\n",
    "            \n",
    "    # Convert to DataFrame\n",
    "    if not predictions:\n",
    "        raise ValueError(\"No valid predictions generated\")\n",
    "        \n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    \n",
    "    # Add confidence intervals\n",
    "    for metric in ['drs', 'uzr', 'oaa']:\n",
    "        pred_df[f'{metric}_150_lower'] = pred_df[f'{metric}_150_pred'] - 1.96 * pred_df[f'{metric}_150_uncert']\n",
    "        pred_df[f'{metric}_150_upper'] = pred_df[f'{metric}_150_pred'] + 1.96 * pred_df[f'{metric}_150_uncert']\n",
    "        \n",
    "    return pred_df\n",
    "\n",
    "# Put model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Generate predictions\n",
    "predictions_2024 = generate_2024_predictions(fielding_df, model, processor)\n",
    "\n",
    "# Add player names\n",
    "name_map = fielding_df[['IDfg', 'Name']].drop_duplicates().set_index('IDfg')['Name']\n",
    "predictions_2024['Name'] = predictions_2024['player_id'].map(name_map)\n",
    "\n",
    "# Sort and display top predictions by position\n",
    "for pos in defensive_config.position_map.keys():\n",
    "    print(f\"\\n=== Top {pos} Defenders (Predicted DRS/150) ===\")\n",
    "    pos_preds = predictions_2024[predictions_2024['position'] == pos].sort_values('drs_150_pred', ascending=False)\n",
    "    print(pos_preds[['Name', 'drs_150_pred', 'drs_150_lower', 'drs_150_upper']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

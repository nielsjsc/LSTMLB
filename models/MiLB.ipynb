{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define the file paths\n",
    "hitters_file_path = os.path.join(current_dir, '..', 'data', 'cleaned_matched_hitters.csv')\n",
    "pitchers_file_path = os.path.join(current_dir, '..', 'data', 'cleaned_matched_pitchers.csv')\n",
    "# Load the datasets\n",
    "hitters_df = pd.read_csv(hitters_file_path)\n",
    "pitchers_df = pd.read_csv(pitchers_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a function to apply label encoding\n",
    "def label_encode(df, columns):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = label_encoder.fit_transform(df[col].astype(str))  # Ensuring it's a string before encoding\n",
    "    return df\n",
    "\n",
    "def preprocess_hitters(hitters_df, filter_years=True):\n",
    "    # Step 1: Filter out rows with Year value of 2023 or 2024 if filter_years is True\n",
    "    if filter_years:\n",
    "        hitters_df = hitters_df[~hitters_df['Year'].isin([2023, 2024])]\n",
    "\n",
    "    # Step 2: Drop irrelevant columns except 'Name'\n",
    "    drop_cols = ['Avg EV', 'Hard Hit%', 'Max EV', 'ETA', 'Risk', 'Sign Yr', 'Year', 'MLB_Debut', 'Games_Played', 'Years_Before_Debut']\n",
    "    hitters_df = hitters_df.drop(columns=drop_cols)\n",
    "\n",
    "    # Step 3: Impute placeholder value for players who have not debuted (Years_Played == 0)\n",
    "    hitters_df['Years_Played'] = hitters_df['Years_Played'].replace(0, np.nan)\n",
    "    hitters_df['Years_Played'] = hitters_df['Years_Played'].fillna(-1)\n",
    "\n",
    "    # Step 4: Calculate WAR_per_Year\n",
    "    hitters_df['WAR_per_Year'] = hitters_df.apply(lambda row: row['WAR_Sum'] / row['Years_Played'] if row['Years_Played'] > 0 else 0, axis=1)\n",
    "    hitters_df = hitters_df.drop(columns=['WAR_Sum', 'Years_Played'])\n",
    "\n",
    "    # Step 5: Handle missing values in Top 100 (fill missing with 999 for unranked players)\n",
    "    hitters_df['Top 100'] = hitters_df['Top 100'].fillna(999)\n",
    "\n",
    "    # Step 6: Impute or handle other missing values\n",
    "    hitters_df['Bat Ctrl'] = hitters_df['Bat Ctrl'].fillna(-1)\n",
    "    hitters_df['Pitch Sel'] = hitters_df['Pitch Sel'].fillna(-1)\n",
    "    hitters_df['Fld'] = hitters_df['Fld'].fillna(hitters_df['Fld'].median())\n",
    "    hitters_df['Bonus'] = hitters_df['Bonus'].fillna(0)\n",
    "    \n",
    "    for col in ['Age', 'Ht', 'Wt']:\n",
    "        hitters_df[col] = hitters_df[col].fillna(hitters_df[col].median())\n",
    "\n",
    "    # Fill categorical values with 'Unknown' for missing entries\n",
    "    hitters_df['B'] = hitters_df['B'].fillna('Unknown')\n",
    "    hitters_df['T'] = hitters_df['T'].fillna('Unknown')\n",
    "    hitters_df['Sign Mkt'] = hitters_df['Sign Mkt'].fillna('Unknown')\n",
    "\n",
    "    # Step 7: Label encode categorical columns\n",
    "    categorical_cols = ['Pos', 'Org', 'B', 'T', 'Sign Mkt']\n",
    "    hitters_df = label_encode(hitters_df, categorical_cols)\n",
    "\n",
    "    # Step 8: Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    hitters_df_scaled = pd.DataFrame(scaler.fit_transform(hitters_df.drop(columns=['Name'])), columns=hitters_df.drop(columns=['Name']).columns)\n",
    "\n",
    "    return hitters_df_scaled, scaler\n",
    "\n",
    "def preprocess_pitchers(pitchers_df, filter_years=True):\n",
    "    # Step 1: Filter out rows with Year value of 2023 or 2024 if filter_years is True\n",
    "    if filter_years:\n",
    "        pitchers_df = pitchers_df[~pitchers_df['Year'].isin([2023, 2024])]\n",
    "\n",
    "    # Step 2: Drop irrelevant columns except 'Name'\n",
    "    drop_cols = ['RPM Break', 'RPM FB', 'TJ Date', 'ETA', 'Risk', 'Sign Yr', 'Year', 'MLB_Debut', 'Fld', 'Avg FB Velo', 'Games_Played','Years_Before_Debut']\n",
    "    pitchers_df = pitchers_df.drop(columns=drop_cols)\n",
    "\n",
    "    # Step 3: Impute placeholder value for players who have not debuted (Years_Played == 0)\n",
    "    pitchers_df['Years_Played'] = pitchers_df['Years_Played'].replace(0, np.nan)\n",
    "    pitchers_df['Years_Played'] = pitchers_df['Years_Played'].fillna(-1)\n",
    "\n",
    "    # Step 4: Calculate WAR_per_Year\n",
    "    pitchers_df['WAR_per_Year'] = pitchers_df.apply(lambda row: row['WAR_Sum'] / row['Years_Played'] if row['Years_Played'] > 0 else 0, axis=1)\n",
    "    pitchers_df = pitchers_df.drop(columns=['WAR_Sum', 'Years_Played'])\n",
    "\n",
    "    # Step 5: Handle missing values in Top 100 (fill missing with 999 for unranked players)\n",
    "    pitchers_df['Top 100'] = pitchers_df['Top 100'].fillna(999)\n",
    "\n",
    "    # Step 6: Handle missing values for pitch-specific skills\n",
    "    pitch_skill_cols = ['SL', 'CB', 'CH', 'Tops']\n",
    "    for col in pitch_skill_cols:\n",
    "        pitchers_df[col] = pitchers_df[col].fillna(0)\n",
    "    \n",
    "    pitchers_df['CMD'] = pitchers_df['CMD'].fillna(pitchers_df['CMD'].median())\n",
    "    pitchers_df['Bonus'] = pitchers_df['Bonus'].fillna(0)\n",
    "\n",
    "    for col in ['Age', 'Ht', 'Wt']:\n",
    "        pitchers_df[col] = pitchers_df[col].fillna(pitchers_df[col].median())\n",
    "    \n",
    "    pitchers_df['B'] = pitchers_df['B'].fillna('Unknown')\n",
    "    pitchers_df['T'] = pitchers_df['T'].fillna('Unknown')\n",
    "    pitchers_df['FB Type'] = pitchers_df['FB Type'].fillna('Unknown')\n",
    "    pitchers_df['Sign Mkt'] = pitchers_df['Sign Mkt'].fillna('Unknown')\n",
    "\n",
    "    # Step 7: Label encode categorical columns\n",
    "    categorical_cols = ['Org', 'Pos', 'B', 'T', 'FB Type', 'Sign Mkt']\n",
    "    pitchers_df = label_encode(pitchers_df, categorical_cols)\n",
    "\n",
    "    # Step 8: Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    pitchers_df_scaled = pd.DataFrame(scaler.fit_transform(pitchers_df.drop(columns=['Name'])), columns=pitchers_df.drop(columns=['Name']).columns)\n",
    "\n",
    "    return pitchers_df_scaled, scaler\n",
    "# Apply preprocessing functions\n",
    "hitters_df, scaler_hitters = preprocess_hitters(hitters_df)\n",
    "pitchers_df, scaler_pitchers = preprocess_pitchers(pitchers_df)\n",
    "\n",
    "# Extract the target variable and features\n",
    "# For hitters\n",
    "y_train_hit = hitters_df['WAR_per_Year']\n",
    "X_train_hit = hitters_df.drop(columns=['WAR_per_Year'])\n",
    "\n",
    "# For pitchers\n",
    "y_train_pitch = pitchers_df['WAR_per_Year']\n",
    "X_train_pitch = pitchers_df.drop(columns=['WAR_per_Year'])\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train_hit, X_val_hit, y_train_hit, y_val_hit = train_test_split(X_train_hit, y_train_hit, test_size=0.2, random_state=42)\n",
    "X_train_pitch, X_val_pitch, y_train_pitch, y_val_pitch = train_test_split(X_train_pitch, y_train_pitch, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "X_train_hit = X_train_hit.apply(pd.to_numeric, errors='ignore')\n",
    "X_val_hit = X_val_hit.apply(pd.to_numeric, errors='ignore')\n",
    "X_train_pitch = X_train_pitch.apply(pd.to_numeric, errors='ignore')\n",
    "X_val_pitch = X_val_pitch.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Fill NaN values with the median of each column\n",
    "X_train_hit = X_train_hit.fillna(X_train_hit.median())\n",
    "X_val_hit = X_val_hit.fillna(X_val_hit.median())\n",
    "X_train_pitch = X_train_pitch.fillna(X_train_pitch.median())\n",
    "X_val_pitch = X_val_pitch.fillna(X_val_pitch.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WARPerYearPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(WARPerYearPredictor, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "        \n",
    "        # Define dropout layers for regularization\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the first fully connected layer and ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply the second fully connected layer and ReLU activation\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply the third fully connected layer and ReLU activation\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply the fourth fully connected layer and ReLU activation\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply the fifth fully connected layer and ReLU activation\n",
    "        x = F.relu(self.fc5(x))\n",
    "        \n",
    "        # Apply the final fully connected layer\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the input dimension based on the number of features in the dataset\n",
    "input_dim_hitters = X_train_hit.shape[1]\n",
    "input_dim_pitchers = X_train_pitch.shape[1]\n",
    "\n",
    "# Instantiate the model for hitters and pitchers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_hitters = WARPerYearPredictor(input_dim=input_dim_hitters).to(device)\n",
    "model_pitchers = WARPerYearPredictor(input_dim=input_dim_pitchers).to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_hitters = optim.Adam(model_hitters.parameters(), lr=learning_rate)\n",
    "optimizer_pitchers = optim.Adam(model_pitchers.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.0271, Val Loss: 0.0226\n",
      "Epoch [10/100], Train Loss: 0.0255, Val Loss: 0.0234\n",
      "Epoch [15/100], Train Loss: 0.0248, Val Loss: 0.0226\n",
      "Epoch [20/100], Train Loss: 0.0239, Val Loss: 0.0220\n",
      "Epoch [25/100], Train Loss: 0.0234, Val Loss: 0.0227\n",
      "Epoch [30/100], Train Loss: 0.0209, Val Loss: 0.0213\n",
      "Epoch [35/100], Train Loss: 0.0214, Val Loss: 0.0210\n",
      "Epoch [40/100], Train Loss: 0.0197, Val Loss: 0.0215\n",
      "Epoch [45/100], Train Loss: 0.0194, Val Loss: 0.0207\n",
      "Epoch [50/100], Train Loss: 0.0190, Val Loss: 0.0204\n",
      "Epoch [55/100], Train Loss: 0.0183, Val Loss: 0.0199\n",
      "Epoch [60/100], Train Loss: 0.0163, Val Loss: 0.0189\n",
      "Epoch [65/100], Train Loss: 0.0178, Val Loss: 0.0195\n",
      "Epoch [70/100], Train Loss: 0.0171, Val Loss: 0.0190\n",
      "Epoch [75/100], Train Loss: 0.0169, Val Loss: 0.0183\n",
      "Epoch [80/100], Train Loss: 0.0164, Val Loss: 0.0186\n",
      "Epoch [85/100], Train Loss: 0.0162, Val Loss: 0.0192\n",
      "Epoch [90/100], Train Loss: 0.0156, Val Loss: 0.0191\n",
      "Epoch [95/100], Train Loss: 0.0144, Val Loss: 0.0188\n",
      "Epoch [100/100], Train Loss: 0.0152, Val Loss: 0.0197\n",
      "Epoch [5/100], Train Loss: 0.0270, Val Loss: 0.0303\n",
      "Epoch [10/100], Train Loss: 0.0260, Val Loss: 0.0299\n",
      "Epoch [15/100], Train Loss: 0.0246, Val Loss: 0.0300\n",
      "Epoch [20/100], Train Loss: 0.0241, Val Loss: 0.0300\n",
      "Epoch [25/100], Train Loss: 0.0240, Val Loss: 0.0296\n",
      "Epoch [30/100], Train Loss: 0.0226, Val Loss: 0.0297\n",
      "Epoch [35/100], Train Loss: 0.0216, Val Loss: 0.0294\n",
      "Epoch [40/100], Train Loss: 0.0198, Val Loss: 0.0295\n",
      "Epoch [45/100], Train Loss: 0.0201, Val Loss: 0.0285\n",
      "Epoch [50/100], Train Loss: 0.0191, Val Loss: 0.0292\n",
      "Epoch [55/100], Train Loss: 0.0196, Val Loss: 0.0284\n",
      "Epoch [60/100], Train Loss: 0.0197, Val Loss: 0.0279\n",
      "Epoch [65/100], Train Loss: 0.0184, Val Loss: 0.0278\n",
      "Epoch [70/100], Train Loss: 0.0174, Val Loss: 0.0276\n",
      "Epoch [75/100], Train Loss: 0.0165, Val Loss: 0.0284\n",
      "Epoch [80/100], Train Loss: 0.0168, Val Loss: 0.0274\n",
      "Epoch [85/100], Train Loss: 0.0162, Val Loss: 0.0275\n",
      "Epoch [90/100], Train Loss: 0.0164, Val Loss: 0.0281\n",
      "Epoch [95/100], Train Loss: 0.0162, Val Loss: 0.0275\n",
      "Epoch [100/100], Train Loss: 0.0163, Val Loss: 0.0278\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, optimizer, criterion, X_train, y_train, X_val, y_val, num_epochs, batch_size, device):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = torch.tensor(X_train[i:i+batch_size].values, dtype=torch.float32).to(device)\n",
    "            y_batch = torch.tensor(y_train[i:i+batch_size].values, dtype=torch.float32).to(device).view(-1, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        train_losses.append(epoch_train_loss / len(X_train))\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_val), batch_size):\n",
    "                X_batch = torch.tensor(X_val[i:i+batch_size].values, dtype=torch.float32).to(device)\n",
    "                y_batch = torch.tensor(y_val[i:i+batch_size].values, dtype=torch.float32).to(device).view(-1, 1)\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(epoch_val_loss / len(X_val))\n",
    "\n",
    "        # Print loss every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Train the model for hitters\n",
    "train_losses_hitters, val_losses_hitters = train_model(\n",
    "    model=model_hitters,\n",
    "    optimizer=optimizer_hitters,\n",
    "    criterion=criterion,\n",
    "    X_train=X_train_hit,\n",
    "    y_train=y_train_hit,\n",
    "    X_val=X_val_hit,\n",
    "    y_val=y_val_hit,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Train the model for pitchers\n",
    "train_losses_pitchers, val_losses_pitchers = train_model(\n",
    "    model=model_pitchers,\n",
    "    optimizer=optimizer_pitchers,\n",
    "    criterion=criterion,\n",
    "    X_train=X_train_pitch,\n",
    "    y_train=y_train_pitch,\n",
    "    X_val=X_val_pitch,\n",
    "    y_val=y_val_pitch,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_hitters_2024: (237, 19)\n",
      "Shape of X_pitchers_2024: (249, 19)\n",
      "Index(['Bat Ctrl', 'Fld', 'Game', 'Hit', 'Org', 'Pitch Sel', 'Pos', 'Raw',\n",
      "       'Spd', 'Age', 'B', 'Bonus', 'FV', 'Ht', 'Org Rk', 'Sign Mkt', 'T',\n",
      "       'Top 100', 'Wt'],\n",
      "      dtype='object')\n",
      "Index(['CB', 'CH', 'CMD', 'FB', 'FB Type', 'Org', 'Pos', 'SL', 'Tops', 'Age',\n",
      "       'B', 'Bonus', 'FV', 'Ht', 'Org Rk', 'Sign Mkt', 'T', 'Top 100', 'Wt'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data\\generated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m pitchers_2024_results \u001b[38;5;241m=\u001b[39m pitchers_2024_results\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop 100\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Save the results to CSV files with a different encoder to maintain Latin players' names\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[43mhitters_2024_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/generated/hitters_2024_predicted_war_6_years.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8-sig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m pitchers_2024_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/generated/pitchers_2024_predicted_war_6_years.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data\\generated'"
     ]
    }
   ],
   "source": [
    "# Reload the datasets\n",
    "new_hitters_df = pd.read_csv(hitters_file_path)\n",
    "new_pitchers_df = pd.read_csv(pitchers_file_path)\n",
    "\n",
    "# Filter the data for rows where the \"Year\" is 2024\n",
    "hitters_2024_df = new_hitters_df[new_hitters_df['Year'] == 2024]\n",
    "pitchers_2024_df = new_pitchers_df[new_pitchers_df['Year'] == 2024]\n",
    "\n",
    "# Extract the Name column\n",
    "hitters_names_2024 = hitters_2024_df['Name']\n",
    "pitchers_names_2024 = pitchers_2024_df['Name']\n",
    "\n",
    "# Preprocess the data without filtering out the year 2024\n",
    "hitters_2024_df, scaler_hitters_2024 = preprocess_hitters(hitters_2024_df, filter_years=False)\n",
    "pitchers_2024_df, scaler_pitchers_2024 = preprocess_pitchers(pitchers_2024_df, filter_years=False)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "hitters_2024_df = hitters_2024_df.apply(pd.to_numeric, errors='ignore')\n",
    "pitchers_2024_df = pitchers_2024_df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Extract features (drop the target variable if it exists)\n",
    "X_hitters_2024 = hitters_2024_df.drop(columns=['WAR_per_Year'], errors='ignore')\n",
    "X_pitchers_2024 = pitchers_2024_df.drop(columns=['WAR_per_Year'], errors='ignore')\n",
    "\n",
    "# Print the shape of the features to ensure they match the model's expectations\n",
    "print(\"Shape of X_hitters_2024:\", X_hitters_2024.shape)\n",
    "print(\"Shape of X_pitchers_2024:\", X_pitchers_2024.shape)\n",
    "# Print column names\n",
    "print(X_hitters_2024.columns)\n",
    "print(X_pitchers_2024.columns)\n",
    "\n",
    "# Convert to tensors\n",
    "X_hitters_2024_tensor = torch.tensor(X_hitters_2024.values, dtype=torch.float32).to(device)\n",
    "X_pitchers_2024_tensor = torch.tensor(X_pitchers_2024.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "model_hitters.eval()\n",
    "model_pitchers.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions_hitters_2024 = model_hitters(X_hitters_2024_tensor).cpu().numpy()\n",
    "    predictions_pitchers_2024 = model_pitchers(X_pitchers_2024_tensor).cpu().numpy()\n",
    "\n",
    "# Extrapolate the predicted WAR per year to 6 years\n",
    "predicted_war_6_years_hitters = predictions_hitters_2024 * 6\n",
    "predicted_war_6_years_pitchers = predictions_pitchers_2024 * 6\n",
    "\n",
    "# Unscale the data\n",
    "hitters_2024_unscaled = pd.DataFrame(scaler_hitters_2024.inverse_transform(hitters_2024_df), columns=hitters_2024_df.columns)\n",
    "pitchers_2024_unscaled = pd.DataFrame(scaler_pitchers_2024.inverse_transform(pitchers_2024_df), columns=pitchers_2024_df.columns)\n",
    "\n",
    "# Create DataFrames with the Name, Top 100, and extrapolated WAR\n",
    "hitters_2024_results = pd.DataFrame({\n",
    "    'Name': hitters_names_2024.values[:len(predicted_war_6_years_hitters)],\n",
    "    'Predicted_WAR_6_Years': predicted_war_6_years_hitters.flatten(),\n",
    "    'Top 100': hitters_2024_unscaled['Top 100'].values[:len(predicted_war_6_years_hitters)]\n",
    "})\n",
    "\n",
    "pitchers_2024_results = pd.DataFrame({\n",
    "    'Name': pitchers_names_2024.values[:len(predicted_war_6_years_pitchers)],\n",
    "    'Predicted_WAR_6_Years': predicted_war_6_years_pitchers.flatten(),\n",
    "    'Top 100': pitchers_2024_unscaled['Top 100'].values[:len(predicted_war_6_years_pitchers)]\n",
    "})\n",
    "\n",
    "# Remove rows with Top 100 value of 999\n",
    "hitters_2024_results = hitters_2024_results[hitters_2024_results['Top 100'] != 999]\n",
    "pitchers_2024_results = pitchers_2024_results[pitchers_2024_results['Top 100'] != 999]\n",
    "\n",
    "# Sort by Top 100\n",
    "hitters_2024_results = hitters_2024_results.sort_values(by='Top 100')\n",
    "pitchers_2024_results = pitchers_2024_results.sort_values(by='Top 100')\n",
    "\n",
    "# Save the results to CSV files with a different encoder to maintain Latin players' names\n",
    "hitters_2024_results.to_csv('../data/generated/hitters_2024_predicted_war_6_years.csv', index=False, encoding='utf-8-sig')\n",
    "pitchers_2024_results.to_csv('../data/generated/pitchers_2024_predicted_war_6_years.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important features for hitters:\n",
      "     Feature  Importance\n",
      "12        FV    0.158152\n",
      "1        Fld    0.128054\n",
      "18        Wt    0.087454\n",
      "4        Org    0.074764\n",
      "13        Ht    0.074427\n",
      "17   Top 100    0.071089\n",
      "3        Hit    0.070858\n",
      "2       Game    0.067161\n",
      "11     Bonus    0.064880\n",
      "15  Sign Mkt    0.064323\n",
      "\n",
      "Top 10 most important features for pitchers:\n",
      "   Feature  Importance\n",
      "13      Ht    0.196904\n",
      "12      FV    0.178889\n",
      "18      Wt    0.111948\n",
      "5      Org    0.085500\n",
      "11   Bonus    0.074292\n",
      "2      CMD    0.073813\n",
      "7       SL    0.073296\n",
      "3       FB    0.064504\n",
      "16       T    0.063721\n",
      "1       CH    0.056556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate permutation feature importance\n",
    "def permutation_feature_importance(model, X_val, y_val, device, n_repeats=5):\n",
    "    baseline_preds = model(torch.tensor(X_val.values, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "    baseline_error = mean_squared_error(y_val, baseline_preds)\n",
    "    \n",
    "    feature_importances = np.zeros(X_val.shape[1])\n",
    "    \n",
    "    for col in range(X_val.shape[1]):\n",
    "        errors = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_val_permuted = X_val.copy()\n",
    "            X_val_permuted.iloc[:, col] = np.random.permutation(X_val_permuted.iloc[:, col])\n",
    "            permuted_preds = model(torch.tensor(X_val_permuted.values, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "            permuted_error = mean_squared_error(y_val, permuted_preds)\n",
    "            errors.append(permuted_error)\n",
    "        feature_importances[col] = np.mean(errors) - baseline_error\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "# Calculate feature importance for hitters\n",
    "hitters_feature_importances = permutation_feature_importance(model_hitters, X_val_hit, y_val_hit, device)\n",
    "\n",
    "# Calculate feature importance for pitchers\n",
    "pitchers_feature_importances = permutation_feature_importance(model_pitchers, X_val_pitch, y_val_pitch, device)\n",
    "\n",
    "# Create DataFrames for feature importances\n",
    "hitters_feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_val_hit.columns,\n",
    "    'Importance': hitters_feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "pitchers_feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_val_pitch.columns,\n",
    "    'Importance': pitchers_feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 most important features for hitters and pitchers\n",
    "print(\"Top 10 most important features for hitters:\")\n",
    "print(hitters_feature_importance_df.head(10))\n",
    "\n",
    "print(\"\\nTop 10 most important features for pitchers:\")\n",
    "print(pitchers_feature_importance_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
